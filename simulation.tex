\section{Parameter und Statistiken einer Simulation}\label{statistiken:sec}

Kombiniert man nun das Szenario, die Agenten und das Zielobjekt, kann man eine Simulation laufen lassen. Im Folgenden werden nun wesentliche Elemente besprochen, die den Ablauf einer solchen Simulation betreffen. In Kapitel~\ref{allgemeines_simulation:sec} werden allgemeine Parameter wie Experiment- und Schrittzahl angesprochen. Kapitel~\ref{definition_probleminstanz:sec} schließt dann mit der Beschreibung einer Probleminstanz an, die in einem Experiment aufgerufen werden. In Kapitel~\ref{abdeckung:sec} wird dann die Formel zur Berechnung der Abdeckung vorgestellt und in Kapitel~\ref{qualitaet:sec} wird schließlich auf die Bestimmung der Qualität eines Algorithmus in einem Szenario eingegangen.


\subsection{Allgemeines}\label{allgemeines_simulation:sec}

Die Statistiken werden jeweils über einen Lauf von 10 Experimenten mit jeweils 10 Probleminstanzen (siehe Kapitel~\ref{definition_probleminstanz:sec}) ermittelt und gemittelt. Abbildung~\ref{statistic_varianz:fig} zeigt, dass 10 Experimente genügen. Dabei wurde jeweils die Varianz von 10 Durchläufen mit aufsteigender Anzahl von Experimenten im Säulenszenario mit sich zufällig bewegenden Agenten berechnet und jeder der 10 Durchläufe wurde mit einem zufälligen \emph{random seed} Wert gestartet. Ab einem Wert von etwa 8 Experimenten fällt die Varianz unter 1\%, was für diese Arbeit als ausreichend erscheint.\\

\begin{figure}[htbp]
\centerline{	
\includegraphics{statistic_varianz.eps}
}
\caption[Varianz der Testergebnisse bei unterschiedlicher Anzahl von Experimenten]{Varianz der Testergebnisse bei unterschiedlicher Anzahl von Experimenten (Säulenszenario, Zielobjekt mit einfacher Richtungsänderung und Geschwindigkeit 2, 8 Agenten mit zufälliger Bewegung)}
\label{statistic_varianz:fig}
\end{figure}




\subsection{Definition einer Probleminstanz}\label{definition_probleminstanz:sec}

Eine einzelne Probleminstanz entspricht hier einem Torus mit einer bestimmten Anfangsbelegung mit bestimmten Objekten und bestimmten Parametern zur Sichtbarkeit, auf dem die Simulation über eine bestimmte Anzahl von Schritten abläuft. Die Anfangsbelegung des Torus ist über einen \emph{random seed} Wert bestimmt. Dieser wird für jede Probleminstanz mit einem neuen Wert initialisiert, der sich aus der Nummer des Experiments und der Nummer der Probleminstanz berechnet. Die Probleminstanzen sind also untereinander unterschiedlich, jedoch  mit anderen Testdurchläufen mit einer anderen Konfiguration vergleichbar. Soweit nicht anders angegeben, werden hier Probleminstanzen der Größe 16x16 Felder betrachtet und laufen über 2.000 Schritte. In den Tabellen angegebenen Werte sind jeweils auf zwei Stellen gerundet.\\

Während eines Testlaufs wird eine ganze Reihe von statistischen Merkmalen erfasst. Wesentliches Merkmal zum Vergleich der Algorithmen ist der Wert der Qualität (siehe Kapitel~\ref{qualitaet:sec}), weitere Merkmale dienen zur Erklärung, warum z.B. ein Algorithmus bei einem Durchlauf schlechte Ergebnisse lieferte, oder dienten zum Testen und Finden von Fehlern oder Schwächen des Simulationsprogramms.\\

\begin{figure}[H]
\setbox0\vbox{\small
Die wesentlichen Merkmale sind:
\begin{enumerate}

\item Anteil von Sprüngen des Zielobjekts (siehe Kapitel~\ref{zielobjekt:sec}), Durchläufe mit hohen Werten sollten verworfen werden,
\item Anteil von blockierten Bewegungen der Agenten,
\item Halbzeitqualität (siehe Kapitel~\ref{qualitaet:sec}) (größere Unterschiede zur ermittelten Qualität deuten auf Potential mit höherer Schrittzahl hin) sowie
\item Abdeckung (siehe Kapitel~\ref{abdeckung:sec}) sowie

\end{enumerate}
}
\centerline{\fbox{\box0}}
\end{figure}


\subsection{Abdeckung}\label{abdeckung:sec}

Die theoretisch maximal mögliche Anzahl an Feldern, die die Agenten innerhalb ihrer Überwachungsreichweite zu einem Zeitpunkt abdecken können, entspricht der Zahl der Agenten multipliziert mit der Zahl der Felder, die ein Agent in seiner Überwachungsreichweite haben kann. Ist dieser Wert größer als die Gesamtzahl aller freien Felder, wird stattdessen dieser Wert benutzt. Teilt man nun die Anzahl der momentan tatsächlich überwachten Felder durch die eben ermittelte maximal mögliche Anzahl an überwachten Felder, dann erhält man die Abdeckung.\\

Bezeichne \(n\) die Anzahl der Agenten, \(f\) die Anzahl der freien Felder, \(u\) die Anzahl der Felder die ein Agent zu einem Zeitpunkt maximal gleichzeitig überwachen kann und \(T\) die momentan überwachten Felder, dann berechnet sich die Abdeckung \(a_{n}(T)\) wie folgt:
\[a_{n}(T) = \frac{T}{min(n u, f)}\]


\subsection{Qualität eines Algorithmus}\label{qualitaet:sec}

Die Messung der Qualität eines Algorithmus bezieht sich in dieser Arbeit auf die Betrachtung des Verhaltens des Algorithmus über einen ganzen Testlauf hinweg. Messungen finden also nicht nur z.B. am Ende oder nur während bestimmten  Probleminstanzen, wie dies bei der Standardimplementierung von XCS der Fall ist.\\

Für die Darstellung der Qualität des Algorithmus werden die einzelnen Probleminstanzen nacheinander aufgereiht, sodass sich z.B. bei 500 Schritten pro Probleminstanz und 10 Problemen pro Experiment eine Gesamtzahl von 5.000 Schritten ergibt. Für jeden einzelnen Schritt wird die Qualität dann über das Mittel aller Experimente berechnet.\\

Zur Darstellung des zeitlichen Verlaufs der Qualität kann es aufgrund der relativ niedrigen Anzahl von Experimenten pro Durchlauf außerdem sinnvoll sein, den gleitenden Durchschnitt über mehrere Schritte anstatt die mittlere Qualität zu einem Zeitpunkt darzustellen. Dies erlaubt eine übersichtlichere Darstellung.\\

In den in dieser Arbeit verwendeten Darstellung des zeitlichen Verlaufs der Qualität wird zu Beginn jeweils der Durchschnitt aller bisherigen Schritte und nach dem \(max_{s}\)-ten Schritt jeweils der Durchschnitt über die letzten \(max_{s}\) Schritte dargestellt werden.\\

Desweiteren wird von einer Halbzeitqualität die Rede sein, hierbei werden bei einem Probleminstanz jeweils nur die letzten \(\frac{max_{s}}{2}\) Schritte für die Gesamtqualität berücksichtigt. Damit kann man beispielsweise untersuchen, ob sich der jeweilige Algorithmus nach dieser Zahl von Schritten bereits an das  Problem angepasst hat oder ob eine Erhöhung der Schrittzahl die Qualität verbessern könnte. Die Betrachtung dieser Statistik hat insbesondere beim Testen es sehr einfach gemacht, festzustellen, ob ein Algorithmus noch Potential hat, d.h. ob eine Erhöhung der Schrittzahl die Qualität weiter steigern würde.\\

\begin{figure}[H]
\setbox0\vbox{\small
\begin{itemize}
\item Sei Hilfsvariable \(q_{eps} = 1\) wenn sich das Zielobjekt in der Überwachungsreichweite eines beliebigen Agenten während Experiment \(e\) in Probleminstanz \(p\) im Schritt \(s\) befindet und \(q_{eps} = 0\) sonst (siehe auch Kapitel~\ref{bewertung:sec}). 
\item Bestimme \(max_{e}\) die Anzahl der durchgeführten Experimente,
\item \(max_{p}\) die Anzahl der Probleminstanzen pro Experiment und
\item \(max_{s}\) die Anzahl der Schritte pro Experiment.
\end{itemize}

Dann berechnet sich die Qualität \(q_{i}\) für einen Schritt \(i\)  wie folgt:
\[q_i = \frac{\sum_{e=0}^{max_{e}} q_{ei}}{max_{e}} \mathrm{~, mit~} q_{ei} = q_{e(\frac{i}{max_{s}})(i \bmod max_{s})}\] 

Die Gesamtqualität \(q\) berechnet sich dann mit:
\[q = \frac{\sum_{i=0}^{max_{p} max_{s}} q_{i}}{max_{p} max_{s}}\]
}
\centerline{\fbox{\box0}}
\end{figure}

\section{Ablauf der Simulation}\label{reihenfolge:sec}

Die Simulation selbst läuft in ineinander geschachtelten Schleifen ab. Jede Konfiguration, die in den abgedruckten Programmen in Kapitel~\ref{implementation:cha} jeweils über die globale Variable \emph{Configuration} angesprochen wird, wird über eine Reihe von Experimenten getestet (10 soweit nicht anders angegeben). Für einen Test wird die Funktion \emph{doOneMultiStepExperiment()} (siehe Programm~\ref{mainExperiment:pro}) mit der aktuellen Nummer des Experiments als Parameter aufgerufen. In der Funktion wird ein neuer \emph{random seed} Wert initialisiert, der Torus auf den Startzustand gesetzt und schließlich die eigentliche Probleminstanz mit der Funktion \emph{doOneMultiStepProblem()} aufgerufen, welche in Programm~\ref{mainProblem:pro} abgebildet ist. Dort werden in einer Schleife alle Schritte durchlaufen und jeweils die Objekte abgearbeitet.\\

In welcher Reihenfolge dies geschieht, wird im Folgenden geklärt. Zusammenfassend ist zu sagen, dass zuerst die aktuelle Qualität und die aktuellen Sensordaten bestimmt werden. Daraus ermittelt jeder Agent die Bewertung für den letzten Schritt und bestimmt eine neue Aktion. Haben Agenten und das Zielobjekt diese Schritte abgeschlossen, werden ihre ermittelten Aktionen in zufälliger Reihenfolge ausgeführt.\\

In Kapitel~\ref{berechnung_problem:sec} wird zuerst der äußere Ablauf einer einzelnen Probleminstanz besprochen. Da sich Zielobjekt und Agenten in unterschiedlichen Geschwindigkeiten bewegen können, wird in Kapitel~\ref{reihenfolge_geschwindigkeiten:sec} die Reihenfolge der Bewegungen in der Simulation diskutiert. Kapitel~\ref{qualitaetsmessung:sec} geht dann auf die Frage ein, wann die Qualität gemessen werden soll und Kapitel~\ref{reihenfolge_reward:sec} geht auf die Frage ein, wann der \emph{base reward} bestimmt wird. Abschluss macht dann eine Zusammenfassung des Ablaufs einer Simulation in Kapitel~\ref{zusammenfassung_simulation:sec}.


\subsection{Berechnung einer Probleminstanz}\label{berechnung_problem:sec}

Bei der Berechnung einer einzelnen Probleminstanz in der Funktion \emph{doOneMultiStepProblem()} stellt sich die Frage nach der Genauigkeit und der Reihenfolge der Abarbeitung, da die Simulation nicht parallel, sondern schrittweise auf einem diskreten Torus abläuft. Dies kann dazu führen, dass je nach Position in der Liste abzuarbeitender Agenten die Informationen über die Umgebung unterschiedlich alt sind. Die Frage ist deshalb, in welcher Reihenfolge folgende Punkte ausgeführt werden: Ermittlung und Auswertung der Sensordaten,  Bewegung der Agenten, Bewertung der Agenten und Messung der Qualität.\\

Da eine Aktion auf Basis der Sensordaten ausgewählt wird, ist die erste Restriktion, dass eine Aktion nach der Verarbeitung der Sensordaten stattfinden muss. Da außerdem Aktionen bewertet werden sollen, also jeweils der Zustand nach der Bewegung mit dem gewünschten Zustand verglichen werden soll, ist die zweite Restriktion, dass die Bewertung einer Aktion nach dessen Ausführung stattfinden muss.\\

Unter diesen Restriktionen ergeben sich folgende zwei Möglichkeiten:

\begin{enumerate}
\item Für alle Agenten werden erst einmal die neuen Sensordaten erfasst und sich für eine Aktion entschieden. Sind alle Agenten abgearbeitet, werden die Aktionen ausgeführt.
\item Die Agenten werden nacheinander abgearbeitet, es werden jeweils neue Sensordaten erfasst, sich für eine neue Aktion entschieden und diese sofort ausgeführt.
\end{enumerate}

Beim zweiten Punkt ergibt sich der Umstand, dass später abgearbeitete Agenten aktuellere Informationen über die Umwelt besitzen. Insbesondere schlägt bei den später ausgeführten Agenten eine Aktion mit geringerer Wahrscheinlichkeit fehl, sofern Hindernisse in der Bewegung beachtet werden. Umgekehrt können früh ausgeführte Agenten eher gute Positionen besetzen. Da dies ein schwierig zu beurteilenden Faktor in die Untersuchungen einbringt, wird für die Simulation die erste Möglichkeit gewählt, jeder Agent entscheidet seine Aktion also auf Basis von Sensordaten vom selben, gemeinsamen Zeitpunkt.\\


\subsection{Reihenfolge bei unterschiedlichen Geschwindigkeiten}\label{reihenfolge_geschwindigkeiten:sec}

Bezüglich der Bewegung ergibt sich eine weitere Frage, nämlich wie unterschiedliche Bewegungsgeschwindigkeiten behandelt werden sollen. Zwar haben alle Agenten eine Einheitsgeschwindigkeit von einem Feld pro Zeiteinheit, jedoch kann sich das Zielobjekt je nach Szenario gleich eine ganze Anzahl von Feldern bewegen (siehe auch Kapitel~\ref{zielobjekt:sec}).\\

Die Entscheidung fiel hier auf eine zufällige Verteilung. Kann sich das Zielobjekt um \(n\) Schritte bewegen, so wird seine Bewegung in \(n\) Einzelschritte unterteilt, die nacheinander mit zufälligen Abständen (d.h. Bewegungen anderer Agenten) ausgeführt werden.\\

Schließlich ist zu klären, wie das Zielobjekt diese weiteren Schritte festlegen soll. Hier wird ein Sonderfall eingeführt, sodass das Zielobjekt in einer Zeiteinheit mehrmals (\(n\)-mal) neue Sensordaten erfassen und sich für eine neue Aktion entscheiden kann.\\



\subsection{Messung der Qualität}\label{qualitaetsmessung:sec}

Bei der Analyse der gerade betrachteten Reihenfolge stellt sich die Frage, wann man die Qualität des Algorithmus messen sollte. Eine Messung nach der Bewegung des Zielobjekts würde bedeuten, dass sich dieses vor der Messung noch optimal positionieren kann. Eine Messung vor der Bewegung bedeutet, dass die Agenten sich relativ zum Zielobjekt noch optimal positionieren können.\\

Eine Messung nach der Bewegung des Zielobjekts bedeutet, dass ein Agent ein Zielobjekt, das sich gerade aus der Überwachungsreichweite herausbewegt, nicht mehr überwachen kann und somit eine tendenziell niedrigere Qualität gemessen wird. Dies gilt insbesondere bei sich intelligent verhaltenden Zielobjekten.\\

Da ein wesentlicher Bestandteil dieser Arbeit die Kollaboration anstatt dem dauernden Verfolgen des Zielobjekts ist, wird ein Bewertungskriterium sein, inwieweit der Einfluss des Zielobjekts minimiert werden kann. Realistisch gesehen, findet die Bewegung des Zielobjekts gleichzeitig mit allen anderen Agenten statt. Die Qualität wird somit nach der Bewegung des Zielobjekts gemessen.\\


\subsection{Reihenfolge der Ermittlung des \emph{base reward} Werts}\label{reihenfolge_reward:sec}

Hat man sich für die Art entschieden, wie die Qualität des Algorithmus bewertet wird, kann man damit fortfahren, sich zu überlegen, wie der einzelne Agent aus der lokalen Sichtweise heraus bestimmt, wie gut sein Verhalten war.\\

Die bisher vorgestellten Agenten in Kapitel~\ref{base_agent_types:sec} sind nicht lernfähig, d.h. es gibt keine Rückkopplung zwischen erfassten Sensordaten und den Heuristiken. Die Agenten, die im Kapitel~\ref{lcs:cha} vorgestellt werden, besitzen dagegen eine solche Rückkopplung. Deshalb stellt sich die Frage, wann geprüft werden soll, ob das Zielobjekt in Überwachungsreichweite ist und wann sich somit ein sogenannter \emph{base reward} Wert ergeben soll. Wesentliche Punkte hierbei sind, dass der Algorithmus sich anhand der Sensordaten selbst bewertet und pro Schritt die Sensordaten nur einmal erhoben werden. Letzteres folgt aus der Standardimplementierung von XCS, wo der \emph{base reward} Wert jeweils genau einer Aktion zugeordnet ist.\\

Aus Standardimplementierung wird außerdem übernommen, dass der \emph{base reward} Wert von binärer Natur ("`Zielobjekt in Überwachungsreichweite"' oder "`Zielobjekt nicht in Überwachungsreichweite"') ist. Deshalb werden Zwischenzustände für diesen Wert, die sich aus der mehrfachen Bewegung des Zielobjekts ergeben könnten (z.B. "`War zwei von drei Schritten in Überwachungsreichweite"' \(\Rightarrow \frac{2}{3}\) \emph{base reward}), ausgeschlossen.\\

Für den \emph{base reward} Wert ergibt sich somit entweder die Möglichkeit, die einzelnen \emph{base reward} Werte jeweils direkt nach der Ausführung einer einzelnen Aktion oder nach Ausführung aller Aktionen der Agenten und des Zielobjekts zu ermitteln. Werden die \emph{base reward} Werte sofort ermittelt, dann bezieht sich der Wert auf die veralteten Sensordaten vor der Aktion, die Aktion selbst würde bei der Ermittlung des \emph{base reward} Werts also ignoriert werden. Würden die Werte erst nach Ausführung aller Aktionen bestimmt, müsste man bis zum nächsten Schritt warten, bis neue Sensordaten ermittelt worden wären.\\


\subsection{Zusammenfassung des Simulationsablaufs}\label{zusammenfassung_simulation:sec}

Im Folgenden ist der Ablauf aller Agenten (inklusive des Zielobjekts) dargestellt. Anzumerken ist, dass für das Zielobjekt zu Beginn in Schritt 2 und 3 nur der erste Schritt berechnet wird. Falls die Geschwindigkeit des Zielobjekts größer als 1 ist, werden in Schritt 5 nach der Ausführung der Aktion direkt neue Sensordaten erfasst und eine neue Aktion berechnet (siehe Kapitel~\ref{reihenfolge:sec}). 

\begin{figure}[H]
\setbox0\vbox{\small
\begin{enumerate}
\item Bestimmung der aktuellen \textbf{Qualität},

\item Erfassung der \textbf{Sensordaten} aller Agenten und des Zielobjekts,

\item Bestimmung der jeweiligen {\bfseries {\em base reward} Werte} für die einzelnen Objekte für den letzten Schritt (bezieht sich auf lernende Agenten),

\item Aktualisierung der Regeln anhand des \emph{base reward} Werts (bezieht sich auf lernende Agenten) sowie

\item \textbf{Wahl der Aktion} anhand der Regeln des jeweiligen Agenten bzw. Zielobjekts.

\item \textbf{Ausführung der Aktion} aller (in zufälliger Reihenfolge, Zielobjekt wiederholt u.U. Schritte 2 und 3 zwischen zwei eigenen Bewegungen).

\end{enumerate}
}
\centerline{\fbox{\box0}}
\end{figure}
