\section{Simulation und erfasste Statistiken}

Beim Testen selbst war es durch die Verwendung der in Kapitel~\ref{qualitaet:sec} erwähnten (und im Simulator berechneten) Halbzeitqualitäten sehr einfach, festzustellen, ob ein Algorithmus noch Potential hatte, d.h. ob eine Erhöhung der Schrittzahl die Qualität weiter steigern würde. Da (im Gegensatz zu den später in Kapitel~\ref{lcs_variants:cha} erwähnten lernenden Algorithmen) keiner der hier vorgestellten Algorithmen lernt und somit statische Regeln besitzt, ist es nicht notwendig, die Qualitäten der Algorithmen bei verschiedener Anzahl von Schritten zu betrachten und zu vergleichen. Die Zahl der Schritte wird somit für alle Tests, soweit nicht anders angegeben, standardmäßig auf 500 festgesetzt. Wie in Kapitel~\ref{analysis_sans_lcs:cha} festgestellt wird, hat die Agentenzahl selbst wenig Einfluss, die Verhältnisse zwischen den Agententypen ist ähnlich. Deshalb werden, soweit nicht anders angegeben, hier immer 8 Agenten getestet. Außerdem sollen in den Statistiken die Werte jeweils über einen Lauf von 10 Experimenten mit jeweils 10 Probleminstanzen (siehe Kapitel~\ref{definition_probleminstanz:sec}) ermittelt und gemittelt werden. 10 Experimente reichen aus um ausreichend akkurate Ergebnisse zu erhalten, wie man in Abbildung~\ref{statistic_varianz:fig} sehen kann. Dabei wurde jeweils die Varianz von 10 Durchläufen mit aufsteigender Anzahl von Experimenten berechnet. Jeder der 10 Durchläufe wurde mit einem zufälligen \emph{random seed} Wert gestartet. Vereinzelt wurde zur besseren Übersicht statt der Qualität die Qualitätsdifferenz angegeben. Sie bezeichnet jeweils die Differenz der Qualität des jeweils betrachteten Algorithmus zur Qualität eines Agenten mit zufälliger Bewegung. 

\begin{figure}[htbp]
\centerline{	
\includegraphics{statistic_varianz.eps}
}
\caption[Varianz der Testergebnisse bei unterschiedlicher Anzahl von Experimenten]{Varianz der Testergebnisse bei unterschiedlicher Anzahl von Experimenten (Säulenszenario, Zielobjekt mit einfacher Richtungsänderung und Geschwindigkeit 2, Agenten mit zufälliger Bewegung)}
\label{statistic_varianz:fig}
\end{figure}

Im Folgenden sollen nun allgemeine Eigenschaften der Simulation erläutert werden.\\

\subsection{Definition einer Probleminstanz}\label{definition_probleminstanz:sec}

Eine einzelne Probleminstanz entspricht hier einem Torus mit einer bestimmten Anfangsbelegung mit bestimmten Objekten und bestimmten Parametern zur Sichtbarkeit, auf dem über die erwähnte Anzahl von Schritten die Simulation abläuft. Die Anfangsbelegung des Torus ist über einen \emph{random seed} Wert bestimmt, wobei bei jeder Probleminstanz mit einem neuen Wert initialisiert wird, der sich aus der Nummer des Experiments und der Nummer des Problems berechnet. Die Probleminstanzen sind also untereinander unterschiedlich, jedoch  mit anderen Testdurchläufen mit einer anderen Konfiguration vergleichbar. Soweit nicht anders angegeben, sollen hier Probleminstanzen der Größe 16x16 Felder betrachtet werden, insbesondere beziehen sich die Ergebnisse der Tests auf diesen Fall. In den jeweiligen Tabellen angegebenen Werte sind auf zwei Stellen gerundet.\\

Während eines Testlaufs wird eine ganze Reihe von statistischen Merkmalen erfasst. Wesentliches Merkmal zum Vergleich der Algorithmen ist der Wert der Qualität (siehe Kapitel~\ref{qualitaet:sec}), weitere Merkmale dienen zur Erklärung, warum z.B. ein Algorithmus bei einem Durchlauf schlechte Ergebnisse lieferte, bzw. dienten zum Testen und Finden von Fehlern oder Schwächen des Simulationsprogramms.\\

\begin{figure}[H]
\setbox0\vbox{\small
Im Einzelnen sind hier zu nennen:
\begin{enumerate}

\item Anteil Sprünge des Zielobjekts (siehe Kapitel~\ref{zielobjekt:sec}), Durchläufe mit hohen Werten müssten verworfen werden,
\item Anteil blockierter Bewegungen der Agenten,
\item Halbzeitqualität (siehe Kapitel~\ref{qualitaet:sec}), größere Unterschiede zur ermittelten Qualität deuten darauf hin, dass sich der Algorithmus noch nicht stabilisiert hat und das Szenario mit höherer Schrittzahl erneut durchgeführt werden sollte,
\item Abdeckung sowie
\item Varianz der individuellen Punkte, ungefähres Maß, inwieweit einzelne Agenten an der Gesamtqualität beteiligt waren.

\end{enumerate}
}
\centerline{\fbox{\box0}}
\end{figure}


\subsection{Abdeckung}

Die theoretisch maximal mögliche Anzahl an Feldern, die die Agenten innerhalb ihrer Überwachungsreichweite zu einem Zeitpunkt haben können, entspricht der Zahl der Agenten multipliziert mit der Zahl der Felder, die ein Agent in seiner Übertragungsreichweite haben kann. Ist dieser Wert größer als die Gesamtzahl aller freien Felder, wird stattdessen dieser Wert benutzt.\\
Teilt man nun die Anzahl der momentan tatsächlich überwachten Felder, durch die eben ermittelte maximal mögliche Anzahl an überwachten Felder, erhält man die Abdeckung, die die Agenten momentan erreichen.\\


\subsection{Qualität eines Algorithmus}\label{qualitaet:sec}

Die Qualität eines Algorithmus bezieht sich in dieser Arbeit auf die Betrachtung des Verhaltens des Algorithmus über einen ganzen Testlauf hinweg, es wird also nicht z.B. nur am Ende gemessen oder (wie bei XCS) nur bei bestimmten Problemen. 

Ein Testlauf mit einer bestimmten Konfiguration wird über mehrere Experimente durchgeführt, wobei in jedem Experiment mehrere Probleme ausgeführt werden. 


Die Qualität eines Algorithmus zu einem Problem wird anhand des Anteils der Gesamtzeit eines Problems berechnet, in der der Algorithmus das Zielobjekt während des Problems überwachen (d.h. das Zielobjekt innerhalb einer Distanz von höchstens \emph{reward range} halten) konnte. 


Die Qualität eines Algorithmus zu einer Anzahl von Problemen (also einem Experiment) wird anhand des Anteils der Gesamtzeit aller Probleme berechnet, die er das Zielobjekt während aller Probleme überwachen konnte.\\
Die Qualität eines Algorithmus entspricht dem Durchschnitt der Qualitäten des Algorithmus mehrerer Experimente.\\

Die Halbzeitqualität eines Algorithmus zu einem Problem entspricht dem Anteil der Zeit, die der Algorithmus das Zielobjekt während jeweils der zweiten Hälfte des Problems überwachen konnte, relativ zur halben Gesamtzeit.\\
Die Halbzeitqualität eines Algorithmus zu einer Anzahl von Problemen entspricht dem Anteil der Zeit, die der Algorithmus das Zielobjekt während jeweils der zweiten Hälfte des Problems überwachen konnte, relativ zur halben Gesamtzeit aller Probleme.\\
Die Halbzeitqualität eines Algorithmus entspricht dem Durchschnitt aller Halbzeitqualitäten des Algorithmus mehrerer Experimente.\\
Ein Vergleich der Qualität mit der Halbzeitqualität eines Algorithmus ermöglicht einen Einblick, wie gut sich der Algorithmus verhält, nachdem er sich auf das Problem bereits eine Zeit lang einstellen konnte.\\

TODO vielleicht noch fett machen  die einzelnen Wörter...


\subsection{Ablauf der Simulation}\label{reihenfolge:sec}

Die Simulation selbst läuft in ineinander geschachtelten Schleifen ab. Jede Konfiguration (in den abgedruckten Programmen jeweils über die globale Variable \emph{Configuration} angesprochen) wird über eine Reihe von Experimenten getestet (10 soweit nicht anders angegeben). Für einen Test wird die Funktion \emph{doOneMultiStepExperiment()} (siehe Programm~\ref{mainExperiment:pro}) mit der aktuellen Nummer des Experiments als Parameter aufgerufen. In der Funktion wird ein neuer \emph{random seed} Wert initialisiert, der Torus auf den Startzustand gesetzt und schließlich das eigentliche Problem mit der Funktion \emph{doOneMultiStepProblem()} aufgerufen, welche in Programm~\ref{mainProblem:pro} abgebildet ist. Dort werden in einer Schleife alle Schritte durchlaufen und jeweils die Objekte abgearbeitet.\\

In welcher Reihenfolge dies geschieht, soll im Folgenden geklärt werden. Zusammenfassend ist zu sagen, dass zuerst die aktuelle Qualität und die aktuellen Sensordaten bestimmt werden. Daraus ermittelt jeder Agent die Bewertung für den letzten Schritt und bestimmt eine neue Aktion. Haben Agenten und das Zielobjekt diese Schritte abgeschlossen, werden ihre ermittelten Aktionen in zufälliger Reihenfolge ausgeführt.\\


Bei der Berechnung eines einzelnen Problems in der Funktion \emph{doOneMultiStepProblem()} stellt sich die Frage nach der Genauigkeit und der Reihenfolge der Abarbeitung, da die Simulation nicht parallel, sondern schrittweise auf einem diskreten Torus abläuft. Dies kann u.U. dazu führen, dass je nach Position in der Liste abzuarbeitender Agenten die Informationen über die Umgebung unterschiedlich alt sind. Die Frage ist deshalb, in welcher Reihenfolge Sensordaten ermittelt, ausgewertet, Agenten bewegt, intern sich selbst bewertet und global die Qualität gemessen wird.\\

Da eine Aktion auf Basis der Sensordaten ausgewählt wird, ist die erste Restriktion, dass eine Aktion nach der Verarbeitung der Sensordaten stattfinden muss. Da außerdem Aktionen bewertet werden sollen, also jeweils der Zustand nach der Bewegung mit dem gewünschten Zustand verglichen werden soll, ist die zweite Restriktion, dass die Bewertung einer Aktion nach dessen Ausführung stattfinden muss.\\

Unter diesen Voraussetzungen ergeben sich folgende zwei Möglichkeiten:

\begin{enumerate}
\item Für alle Agenten werden erst einmal die neuen Sensordaten erfasst und sich für eine Aktion entschieden. Sind alle Agenten abgearbeitet, werden die Aktionen ausgeführt.
\item Die Agenten werden nacheinander abgearbeitet, es werden jeweils neue Sensordaten erfasst, sich für eine neue Aktion entschieden und diese sofort ausgeführt.
\end{enumerate}

Beim zweiten Punkt ergibt sich der Umstand, dass später abgearbeitete Agenten aktuellere Informationen über die Umwelt besitzen, insbesondere schlägt bei den später ausgeführten Agenten eine Aktion mit geringerer Wahrscheinlichkeit fehl, sofern Hindernisse in der Bewegung beachtet werden. Umgekehrt können früh ausgeführte Agenten eher gute Positionen besitzen. Da diese zwei Umstände ein schwierig zu beurteilenden Faktor in die Untersuchungen einbringen, wird für die Simulation Punkt 1 gewählt, jeder Agent entscheidet seine Aktion also auf Basis von Sensordaten vom selben, gemeinsamen Zeitpunkt.\\


\subsection{Reihenfolge bei unterschiedlichen Bewegungsgeschwindigkeiten}

Bezüglich der Bewegung ergibt sich eine weitere Frage, nämlich wie unterschiedliche Bewegungsgeschwindigkeiten behandelt werden sollen. Zwar haben alle Agenten eine Einheitsgeschwindigkeit von einem Feld pro Zeiteinheit, jedoch kann sich das Zielobjekt je nach Szenario gleich eine ganze Anzahl von Feldern bewegen (siehe auch Kapitel~\ref{zielobjekt:sec}).\\

Die Entscheidung fiel hier auf eine zufällige Verteilung. Kann sich das Zielobjekt um \(n\) Schritte bewegen, so wird seine Bewegung in \(n\) Einzelschritte unterteilt, die nacheinander mit zufälligen Abständen (d.h. Bewegungen anderer Agenten) ausgeführt werden.\\

Eine weitere Frage ist, wie das Zielobjekt diese weiteren Schritte festlegen soll. Hier soll ein Sonderfall eingeführt werden, sodass das Zielobjekt in einer Zeiteinheit mehrmals (\(n\)-mal) neue Sensordaten erfassen und sich für eine neue Aktion entscheiden kann.\\



\subsection{Messung der Qualität}\label{qualitaetsmessung:sec}

Bei der Analyse der oben betrachteten Reihenfolge stellt sich die Frage, wann man die Qualität des Algorithmus messen sollte. Die Antwort hängt davon ab, was man denn nun eigentlich erreichen möchte. 
Der naheliegendste Messzeitpunkt ist dann gegeben, nachdem sich alle Agenten bewegt haben. Da die Agenten und das Zielobjekt in einem Durchlauf gemeinsam nacheinander bewegt werden, stellt sich die Frage nicht, ob womöglich vor der Bewegung des Zielobjekts die Qualität gemessen werden soll.
Eine Messung nach der Bewegung des Zielobjekts würde diesem erlauben, sich vor jeder Messung optimal zu positionieren, was in einer geringeren Qualität für den Algorithmus resultiert, da sich das Zielobjekt aus der Überwachungsreichweite anderer Agenten hinausbewegen kann. Letztlich ist es eine Frage der Problemstellung. Eine Messung nach der Bewegung des Zielobjekts bedeutet letztlich, dass ein Agent ein Zielobjekt, das sich gerade aus der Überwachungsreichweite herausbewegt, nicht mehr überwachen kann und somit ein tendenziell niedrigere Qualität gemessen wird, insbesondere bei sich intelligent verhaltenden Zielobjekten.\\

Da ein wesentlicher Bestandteil dieser Arbeit die Kollaboration (und somit die Abdeckung des Torus anstatt dem dauernden Verfolgen des Zielobjekts) ist, soll ein Bewertungskriterium sein, inwieweit der Einfluss des Zielobjekts minimiert werden kann. Auch findet, wenn man vom realistischen Fall ausgeht, die Bewegung des Zielobjekts gleichzeitig mit allen anderen Agenten statt. Die Qualität wird somit nach der Bewegung des Zielobjekts gemessen. Die Überlegung unterstreicht auch nochmal, dass es besser ist, das Zielobjekt insgesamt wie einen normalen (aber sich mehrmals bewegenden) Agenten zu behandeln.\\


\subsection{Reihenfolge der Ermittlung des \emph{base reward}}

Hat man sich für die Art entschieden, wie die Qualität des Algorithmus bewertet wird, kann man damit fortfahren, sich zu überlegen, wie der einzelne Agent aus der lokalen Sichtweise heraus bestimmt, wie gut sein Verhalten war. Bei den bisher vorgestellten Agenten in Kapitel~\ref{base_agent_types:sec} haben die Agenten nicht gelernt, d.h. es gab keine Rückkopplung zwischen erfassten Sensordaten und den Regeln, nach denen die nächsten Aktionen entschieden werden. Die Agenten, die im Kapitel~\ref{lcs:cha} vorgestellt werden, besitzen dagegen eine solche Rückkopplung. Deshalb stellt sich die Frage, wann geprüft werden soll, ob das Zielobjekt in Überwachungsreichweite ist und wann sich somit ein sogenannter \emph{base reward} ergeben soll.\\

Wesentliche Punkte hierbei sind, dass der Algorithmus sich anhand der Sensordaten selbst bewertet und pro Schritt die Sensordaten nur einmal erhoben werden. Letzteres folgt aus der Auslegung von XCS, der in der Standardimplementation darauf ausgelegt ist, dass der \emph{base reward} Wert jeweils genau einer Aktion zugeordnet ist. Daraus ergibt sich auch, dass der \emph{base reward} von binärer Natur ("`Zielobjekt in Überwachungsreichweite"' oder "`Zielobjekt nicht in Überwachungsreichweite"') ist, weshalb Zwischenzustände für diesen Wert, der sich aus der mehrfachen Bewegung des Zielobjekts ergeben könnte (z.B. "`War zwei von drei Schritten in Überwachungsreichweite"' \(\Rightarrow \frac{2}{3}\) \emph{base reward}), ausgeschlossen werden soll. Insbesondere würde dies eine mehrfache Erhebung der Sensordaten erfordern.\\

Für den \emph{base reward} ergibt sich somit entweder die Möglichkeit die einzelnen \emph{base reward} Werte jeweils direkt nach der Ausführung einer einzelnen Aktion oder nach Ausführung aller Aktionen der Agenten und des Zielobjekts zu ermitteln. Werden die \emph{base reward} Werte sofort ermittelt, dann bezieht sich der Wert auf die veralteten Sensordaten vor der Aktion, die Aktion selbst würde bei der Ermittlung des \emph{base reward} Werts also ignoriert werden. Werden die Werte erst nach Ausführung aller Aktionen bestimmt, müsste man bis zum nächsten Schritt warten, bis neue Sensordaten ermittelt worden sind.

TODO

\subsection{Zusammenfassung des Simulationsablaufs}

Im Folgenden ist der Ablauf aller Agenten (inklusive des Zielobjekts) dargestellt. Anzumerken ist, dass für das Zielobjekt zu Beginn in Schritt 2 und 3 nur der erste Schritt berechnet wird. Falls die Geschwindigkeit des Zielobjekts größer als 1 ist, werden (wie am Ende in Kapitel~\ref{reihenfolge:sec} angemerkt) in Schritt 5 nach der Ausführung der Aktion direkt neue Sensordaten erfasst und eine neue Aktion berechnet. 

\begin{figure}[H]
\setbox0\vbox{\small
Insgesamt ergibt sich also folgender Ablauf:

\begin{enumerate}
\item Bestimmen der aktuellen \textbf{Qualität},

\item Erfassung der \textbf{Sensordaten} aller Agenten und des Zielobjekts,

\item Bestimmung der jeweiligen {\bfseries {\em base reward} Werte} für die einzelnen Objekte für den letzten Schritt (bezieht sich auf lernende Agenten),

\item Aktualisierung der Regeln anhand des \emph{base reward} Werts (bezieht sich auf lernende Agenten),

\item \textbf{Wahl der Aktion} anhand der Regeln des jeweiligen Agenten bzw. Zielobjekts sowie

\item \textbf{Ausführung der Aktion} aller (in zufälliger Reihenfolge, Zielobjekt wiederholt u.U. Schritte 2 und 3 zwischen zwei eigenen Bewegungen).

\end{enumerate}
}
\centerline{\fbox{\box0}}
\end{figure}
