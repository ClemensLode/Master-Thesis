\chapter{Parameter}\label{cha:parameter}

Die Einstellungen der XCS Parameter der durchgeführten Experimente entsprechen weitgehend den Vorschlägen in~\cite{Butz} (``Commonly Used Parameter Settings''). Eine Auflistung findet sich in Tabelle~\ref{table:lcs_parameter}. Im Folgenden sollen Parameter besprochen werden, die entweder in der Empfehlung offen gelassen sind, also klar vom jeweiligen Szenario abhängen, und solche, bei denen von der Empfehlung abgewichen wurde.\\
Mitunter führen andere Parametereinstellungen auch zu wesentlich besseren Ergebnissen. Dies muss man aber vorsichtig bewerten, wenn die erreichte Qualität unter der des zufälligen Algorithmus liegt, da eine Auswirkung sein kann, dass der Algorithmus nicht besser lernt, sondern sich umgekehrt eher wie der zufällige Algorithmus verhält. Ein Vergleich mit der Qualität des zufälligen Algorithmus wird deswegen jeweils immer angegeben.\\

\section{Max population \emph{N}}\label{sec:max_population_parameter}

Der Wert von \emph{max population} bezeichnet die maximalen Größe der \emph{classifier set} Liste. Ein größerer Wert verlängert die Laufzeit linear (siehe~\ref{empty_grid_time_maxpop:fig}), ein kleinerer Wert erhöht die Konkurrenz zwischen den \emph{classifiers}. Größere Werte erlauben eine bessere Anpassung, da weniger \emph{classifier} während eines Laufs gelöscht werden müssen und mehr Plätze zur Speicherung der Erfahrungen zur Verfügung steht. Auf der anderen Seite werden mehr Schritte benötigt um die für die jeweiligen \emph{classifier} ausreichend Erfahrung zu sammeln (siehe~\ref{empty_grid_quality_maxpop:fig}).\\
Für den Overhead (Benutzung des zufälligen Algorithmus ohne LCS) ergab sich eine mittlere Laufzeit von \(1.77\) Sekunden pro Experiment bei 500 Schritten (bzw. \(6.65\) Sekunden bei 2000 Schritten), was die anfängliche Stagnierung bis \(N = 32\) erklärt.\\
In den Tests wird \textbf{\(N = 128\)} gesetzt, was als ausreichender Kompromiss zwischen den erwähnten Faktoren erscheint.

\begin{figure}[htbp]
\centerline{	
\includegraphics{empty_grid_time_maxpop.eps}
}
\caption[Auswirkung des Parameters \emph{max population N} auf Laufzeit (leeres Szenario)] {Darstellung Auswirkung des Parameters \emph{max population N} auf die Laufzeit im leeren Szenario, zufälliger Bewegung des Zielobjekts, 8 Agenten mit LCS Algorithmus und über 10 Probleme, gemittelt über 10 Experimente}
\label{empty_grid_time_maxpop:fig}
\end{figure}

\begin{figure}[htbp]
\centerline{	
\includegraphics{empty_grid_quality_maxpop.eps}
}
\caption[Auswirkung des Parameters \emph{max population N} auf Qualität (leeres Szenario)] {Darstellung der Auswirkung des Parameters \emph{max population N} auf die Qualität im leeren Szenario, zufälliger Bewegung des Zielobjekts, 8 Agenten mit LCS Algorithmus und über 10 Probleme, gemittelt über 10 Experimente}
\label{empty_grid_quality_maxpop:fig}
\end{figure}

\section{Maximalwert \emph{reward}}\label{sec:maximalwert_rho}

Der Wert der bei der Bewertung als \emph{reward} vergeben wird hat lediglich ästhetische Auswirkungen und wurde auf \(1.0\) gesetzt. In der Standardimplementation von XCS (siehe~\ref{multistep_calc_reward:fig}) ist der maximale \emph{reward} äquivalent mit dem Maximalwert von \(\rho\), da das Problem bei jedem positiven \emph{reward} Wert neugestartet wird, also entweder der \emph{reward} Wert aus dem letzten Schritt also immer \(0\) ist oder \emph{maxPrediction} auf \(0\) gesetzt wurde, und \(\rho = \) \emph{reward} \(+~\gamma \) \emph{maxPrediction} gilt.\\

In den hier vorgestellten XCS Varianten wird dagegen der \emph{reward} Wert absteigend, zusammen mit dem \emph{maxPrediction} Wert, an frühere \emph{actionSet} Listen verteilt, \(\rho\) kann also größer als \(1.0\) werden. In diesem Bereich ist noch Bedarf an theoretischer Forschung, in Tests haben sich Werte bis \(3.0\) ergeben, welche aber vom jeweiligen Szenario abhängen. Wird das Zielobjekt (z.B. wegen Hindernissen oder großen Torusdimensionen) eher selten gesehen, fällt der Wert geringer aus.\\

\section{Accuracy equality}
TODO Abschnitt entfernen
Der Parameter \(\epsilon_{0}\) gibt an, unter welchem Wert zwei \emph{accuracy} Werte als gleich gelten sollen. Dies ist insbesondere bei der \emph{subsummation} Funktion und der Berechnung des \emph{accuracy} Werts von Bedeutung. In der Literatur~\cite{Butz} wird als Regel genannt, dass der Wert auf etwa 1\% des Maximalwerts von \(\rho\) gesetzt werden soll, den der erwartete Reward annehmen kann. Aufgrund der Überlegungen in~\ref{maximalwert_rho:sec} setzen wir \(\epsilon_{0}\) für die neuen XCS Varianten deshalb auf \(0.05\), während wir für die Standardimplementation von XCS \(\epsilon_{0} = 0.01\) lassen. Die Entscheidung wird auch durch Tests (siehe~\ref{table:epsilon}) bestätigt.
TODONein, 0.01 lassen...

\section{Prediction discount $\gamma$}
TODO Abschnitt entfernen
Auch für den Wert \emph{prediction discount} \(\gamma\) hat sich ein etwas höherer Wert als sinnvoll erwiesen, als standardmäßig benutzt wird. Laut~\cite{Butz} hängt der Wert auch vom verwendeten Szenario ab. Ein höherer Wert für \(\gamma\) bedeutet, dass die Höhe des Werts, der über \emph{maxPrediction} weitergegeben wird, mit zeitlichem Abstand zur ursprünglichen Bewertung mit einem \emph{reward}, weniger schnell abfällt, wodurch eine längere Verkettung von \emph{reward} Werten möglich ist. Umgekehrt führen zu hohe Werte für \(\gamma\) zu der positiven Bewertung von \emph{classifiers} die am Erfolg gar nicht beteiligt waren, was sich negativ auf die Qualität auswirken kann.

Tabelle~\ref{table:prediction_discount} zeigt einen Vergleich der Qualität mit dem Standardwert \(\gamma = 0.71\) und dem für die in dieser Arbeit verwendeten Testszenarien gewählten Wert \(\gamma = 0.95\).\\

TODO 0.71 lassen


\section{Lernrate}\label{sec:learnrate_parameter}

Für die Lernrate \(\beta\) hat sich ein etwas niedrigerer als in der Literatur angegebener Wert (\(0.01\)) als sinnvoll erwiesen. 


Auch dieser Parameter ist szenariospezifisch, über die konkrete Begründung kann nur spekuliert werden, die Schwierigkeit des Szenarios 
TODO

Vergleichende Tests (siehe Abbildung~\ref{pillar_learning_rate_quality:fig} mit niedrigerem bzw. höherem Wert haben zu einer etwas schlechteren Qualität geführt.

\begin{figure}[htbp]
\centerline{	
\includegraphics{pillar_learning_rate_quality.eps}
}
\caption[Auswirkung des Parameters \emph{learning rate} $\beta$ auf Qualität (Säulenszenario)] {Darstellung Auswirkung des Parameters \emph{learning rate} $\beta$ auf die Qualität im Säulenszenario, zufälliger Bewegung des Zielobjekts, 8 Agenten mit LCS Algorithmus und über 10 Probleme, gemittelt über 10 Experimente}
\label{pillar_learning_rate_quality:fig}
\end{figure}



\section{Prediction init $p_{i}$}\label{sec:prediction_init}

In der Literatur werden Werte nahe Null bzw. 1\% von \(\rho\) als Initialisierung für den \emph{prediction} Wert eines \emph{classifiers} angegeben. Wählt man einen Wert, der näher am Durchschnitt der \emph{prediction} Werte der \emph{classifier} liegt, die sich in den besten Lösungen am Ende eines Testdurchlaufs befinden, so ist zu erwarten, dass die Anzahl der benötigten Aktualisierungen des \emph{prediction} Werts geringer ausfällt, das System also schneller konvergiert. Diese Überlegung wird bestätigt durch entsprechende Tests (siehe~\ref{pillar_lcs_prediction_init_quality:fig}).\\
Wir setzen somit für LCS den Parameter auf \(p_{i} = 0.5\).\\
TODO Standardverfahren?

\begin{figure}[htbp]
\centerline{	
\includegraphics{pillar_lcs_prediction_init_quality.eps}
}
\caption[Auswirkung des Parameters \emph{prediction init} $p_{i}$ auf Qualität (Säulenszenario)] {Darstellung Auswirkung des Parameters \emph{prediction init} $p_{i}$ auf die Qualität im Säulenszenario, zufälliger Bewegung des Zielobjekts, 8 Agenten mit LCS Algorithmus und über 10 Probleme, gemittelt über 10 Experimente}
\label{pillar_lcs_prediction_init_quality:fig}
\end{figure}


\section{Übersicht über alle Parameterwerte}
\begin{table}[ht]
\caption{Verwendete Parameter (soweit nicht anders angegeben) und Standardparameter}
\centering
\begin{tabular}{c c c}
\hline\hline
Parameter & Wert & Standardwert ~\cite{Butz}\\ [0.5ex]
\hline
Max population \(N\) & \textbf{128} (siehe~\ref{sec:max_population_parameter})\\
Max value \(\rho\) & \textbf{1.0} (siehe~\ref{sec:maximalwert_rho}) & [10000]\\
Fraction mean fitness \(\delta\) & 0.1 & [0.1]\\
Deletion threshold \(\theta_{\mathrm{del}}\) & 20.0 & [\(\sim\) 20.0]\\
Subsumption threshold \(\theta_{\mathrm{sub}}\) & 20.0 & [20.0+]\\
Covering \(\#\) probability \(P_{\#}\) & 0.5 & [\(\sim\) 0.33]\\
GAthreshold \(\theta_{\mathrm{GA}}\) & 25.0 & [25-50]\\
Mutation probability \(\mu\) & \(0.05\) & [0.01-0.05]\\
Prediction error reduction & 0.25 & [0.25]\\
Fitness reduction & \(0.1\) & [0.1]\\

Prediction init \(p_{i}\) & \textbf{0.5} (siehe~\ref{sec:prediction_init}) & [\(\sim\) 0]\\
Prediction error init \(\epsilon_{i}\) & 0.0 & [0.0]\\
Fitness init \(F_{i}\) & \(0.01\) &  [0.01]\\
Accuracy equality \(\epsilon_{0}\) & \textbf{0.05} & [\emph{1\% des größten Werts}]\\
Accuracy calculation \(\alpha\) & 0.1 & [0.1]\\
Accuracy power \(\nu\) & 5.0 & [5.0]\\
Prediction discount \(\gamma\) & 0.71 & [0.71]\\

Learning rate \(\beta\) & \textbf{0.01} (siehe~\ref{sec:learnrate_parameter}) & [0.1-0.2]\\

exploration probability & 0.5 (siehe~\ref{sec:subsummation}) & [\(\sim\) 0.5]\\ [0.5ex]

\hline
\end{tabular}
\label{table:lcs_parameter}
\end{table}




