\chapter{Parameter}\label{cha:parameter}

Die Einstellungen der XCS Parameter der durchgeführten Experimente entsprechen weitgehend den Vorschlägen in~\cite{butz01algorithmic} (``Commonly Used Parameter Settings''). Eine Auflistung findet sich in Tabelle~\ref{table:lcs_parameter}. Im Folgenden sollen Parameter besprochen werden, die entweder in der Empfehlung offen gelassen sind, also klar vom jeweiligen Szenario abhängen, und solche, bei denen von der Empfehlung abgewichen wurde.\\
Mitunter führen andere Parametereinstellungen auch zu wesentlich besseren Ergebnissen. Dies muss man aber vorsichtig bewerten, wenn die erreichte Qualität unter der des zufälligen Algorithmus liegt, da eine Auswirkung sein kann, dass der Algorithmus nicht besser lernt, sondern sich umgekehrt eher wie der zufällige Algorithmus verhält. Ein Vergleich mit der Qualität des zufälligen Algorithmus wird deswegen jeweils immer angegeben.\\
Anzumerken sei, dass alle Tests jeweils mit den in Tabelle~\ref{table:lcs_parameter} angegebenen Parameterwerten durchgeführt wurden und bei jedem Test jeweils nur der zu untersuchende Wert verändert wurde. Um  synchronisierte und vergleichbare Daten zu haben, wurden die Tests deshalb in mehreren Etappen durchgeführt, die angegebenen Testergebnisse entsprechen jeweils den endgültigen Ergebnissen.

\section{Parameter \emph{max population N}}\label{sec:max_population_parameter}

Der Wert von \emph{max population N} bezeichnet die maximalen Größe der \emph{classifier set} Liste. Bei der Wahl eines geeigneten Werts spielt insbesondere die Laufzeit eine Rolle. Für den Overhead (d.h. die Zeit, die 8 Agenten mit zufälliger Bewegung benötigen) ergab sich eine mittlere Laufzeit von \(1,67\)s pro Experiment bei 500 Schritten (bzw. \(6,50\)s bei 2000 Schritten), was die anfängliche Stagnierung bis \(N = 32\) erklärt. Zieht man diesen von den Messwerten (siehe Abbildung~\ref{empty_grid_time_maxpop:fig}) ab, erhält man im betrachteten Wertebereich einen nahezu linearen Verlauf (siehe~\ref{linear_pop_time:fig}, ab \(N > 128\)). Der fallende Verlauf bis 128 erklärt sich durch den Overhead des XCS Algorithmus selbst.\\

Größere Werte für \(N\) erlauben eine bessere Anpassung, da weniger \emph{classifier} während eines Laufs gelöscht werden müssen und mehr Plätze zur Speicherung der Erfahrungen zur Verfügung steht. Auf der anderen Seite werden mehr Schritte benötigt um die für die jeweiligen \emph{classifier} ausreichend Erfahrung zu sammeln (siehe Abbildung~\ref{empty_grid_quality_maxpop:fig}) und, wie oben demonstriert, auch eine längere Laufzeit.\\
Ein zu kleiner Wert erhöht dagegen die Konkurrenz zwischen den \emph{classifier}, da einzelne \emph{classifier} mit höherer Wahrscheinlichkeit von besseren \emph{classifier} verdrängt und somit gelöscht werden.\\

Die Tests liefen auf einem T7500, 2.2 GHz in einem einzelnen Thread. Als Vergleich hierzu wurde auch der Einfluss der Kartengröße auf die Laufzeit betrachtet, wie in Abbildung~\ref{time_map_size_correlation:fig} zu sehen, ist der Einfluss auf die Laufzeit im getesteten Bereich (256 - 1024) ohne Bedeutung.\\

In den Tests wird somit \textbf{\(N = 128\)} gesetzt, was als ausreichender Kompromiss zwischen den erwähnten Faktoren erscheint.

\begin{figure}[htbp]
\centerline{	
\includegraphics{time_map_size_correlation.eps}
}
\caption[Auswirkung der Torusgröße auf die Laufzeit (leeres Szenario)] {Darstellung der Auswirkung der Torusgröße auf die Laufzeit im leeren Szenario, zufälliger Bewegung des Zielobjekts, 8 sich zufällig bewegenden Agenten}
\label{time_map_size_correlation:fig}
\end{figure}

\begin{figure}[htbp]
\centerline{	
\includegraphics{empty_grid_time_maxpop.eps}
}
\caption[Auswirkung des Parameters \emph{max population N} auf Laufzeit (leeres Szenario)] {Darstellung der Auswirkung des Parameters \emph{max population N} auf die Laufzeit im leeren Szenario, zufälliger Bewegung des Zielobjekts, 8 Agenten mit SXCS Algorithmus}
\label{empty_grid_time_maxpop:fig}
\end{figure}

\begin{figure}[htbp]
\centerline{	
\includegraphics{linear_pop_time.eps}
}
\caption[Verhältnis Laufzeit zu \emph{max population N} (leeres Szenario)] {Darstellung der Auswirkung des Parameters \emph{max population N} auf das Verhältnis der Laufzeit zu \(N\) im leeren Szenario, zufälliger Bewegung des Zielobjekts, 8 Agenten mit SXCS Algorithmus}
\label{linear_pop_time:fig}
\end{figure}


\begin{figure}[htbp]
\centerline{	
\includegraphics{empty_grid_quality_maxpop.eps}
}
\caption[Auswirkung des Parameters \emph{max population N} auf Qualität (leeres Szenario)] {Darstellung der Auswirkung des Parameters \emph{max population N} auf die Qualität im leeren Szenario, zufälliger Bewegung des Zielobjekts, 8 Agenten mit LCS Algorithmus}
\label{empty_grid_quality_maxpop:fig}
\end{figure}

\section{Maximalwert \emph{reward}}\label{sec:maximalwert_rho}
TODO
Der Wert der bei der Bewertung als \emph{reward} vergeben wird hat lediglich ästhetische Auswirkungen und wurde auf \(1.0\) gesetzt. In der Standardimplementation von XCS (siehe Abbildung~\ref{multistep_calc_reward:fig}) ist der maximale \emph{reward} äquivalent mit dem Maximalwert von \(\rho\), da das Problem bei jedem positiven \emph{reward} Wert neugestartet wird, also entweder der \emph{reward} Wert aus dem letzten Schritt also immer \(0\) ist oder \emph{maxPrediction} auf \(0\) gesetzt wurde, und \(\rho = \) \emph{reward} \(+~\gamma \) \emph{maxPrediction} gilt.\\

In den hier vorgestellten XCS Varianten wird dagegen der \emph{reward} Wert absteigend, zusammen mit dem \emph{maxPrediction} Wert, an frühere \emph{actionSet} Listen verteilt, \(\rho\) kann also größer als \(1.0\) werden. In diesem Bereich ist noch Bedarf an theoretischer Forschung, in Tests haben sich Werte bis \(3.0\) ergeben, welche aber vom jeweiligen Szenario abhängen. Wird das Zielobjekt (z.B. wegen Hindernissen oder großen Torusdimensionen) eher selten gesehen, fällt der Wert geringer aus.\\

\section{Parameter \emph{accuracy equality} $\epsilon_{0}$}
TODO 
Der Parameter \(\epsilon_{0}\) gibt an, unter welchem Wert zwei \emph{accuracy} Werte als gleich gelten sollen. Dies ist insbesondere bei der \emph{subsummation} Funktion und der Berechnung des \emph{accuracy} Werts von Bedeutung. In der Literatur~\cite{butz01algorithmic} wird als Regel genannt, dass der Wert auf etwa 1\% des Maximalwerts von \(\rho\) gesetzt werden soll, den der erwartete Reward annehmen kann. Aufgrund der Überlegungen in~\ref{sec:maximalwert_rho} wird \(\epsilon_{0}\) für die neuen XCS Varianten auf \(0.02\) gesetzt, während es für die Standardimplementation von XCS auf \(0.01\) gesetzt wird. Ein Testdurchlauf auf dem Säulenszenario (siehe Abbildung~\ref{pillar_epsilon0:fig}) ergibt aber, dass der Parameter keine besondere Auswirkung hat, weshalb der Wert auf \(0.01\) belassen wird.

\begin{figure}[htbp]
\centerline{	
\includegraphics{pillar_epsilon0.eps}
}
\caption[Auswirkung des Parameters \emph{accuracy equality} $\epsilon_{0}$ auf die Qualität (Säulenszenario)] {Auswirkung des Parameters  \emph{accuracy equality} $\epsilon_{0}$ auf die Qualität im Säulenszenario, zufälliger Bewegung des Zielobjekts, 8 Agenten mit SXCS Algorithmus}
\label{pillar_epsilon0:fig}
\end{figure}

\section{Parameter \emph{reward prediction discount} $\gamma$}


%%sxcs gut: 0.4 p#, kein random start, kein GA
dsxcs gut: alles an TODO maxpred überprüfen...


Der Einfluss von \(\gamma\) ist zwar vorhanden, aber sehr gering. 
TODO

TODO Reward prediction unnötig bei speed 2, pillar, random

TODO Abschnitt entfernen
Auch für den Wert \emph{reward prediction discount} \(\gamma\) hat sich ein etwas höherer Wert als sinnvoll erwiesen, als standardmäßig benutzt wird. Laut~\cite{butz01algorithmic} hängt der Wert auch vom verwendeten Szenario ab. Ein höherer Wert für \(\gamma\) bedeutet, dass die Höhe des Werts, der über \emph{maxPrediction} weitergegeben wird, mit zeitlichem Abstand zur ursprünglichen Bewertung mit einem \emph{reward}, weniger schnell abfällt, wodurch eine längere Verkettung von \emph{reward} Werten möglich ist. Umgekehrt führen zu hohe Werte für \(\gamma\) zu der positiven Bewertung von \emph{classifiers} die am Erfolg gar nicht beteiligt waren, was sich negativ auf die Qualität auswirken kann.

Tabelle~\ref{table:prediction_discount} zeigt einen Vergleich der Qualität mit dem Standardwert \(\gamma = 0.71\) und dem für die in dieser Arbeit verwendeten Testszenarien gewählten Wert \(\gamma = 0.95\).\\

TODO 0.71 lassen

auch mit Geschwindigkeit 0.1 oder so testen

TODOTabelle prediction discount

\section{Parameter Lernrate $\beta$}\label{sec:learnrate_parameter}

Für die Lernrate \(\beta\) hat sich ein etwas niedrigerer als in der Literatur angegebener Wert (\(0.01\)) als erfolgreich erwiesen. Die Lernrate bestimmt, wie stark ein ermittelter \emph{reward} Wert den \emph{reward prediction}, \emph{reward prediction error}, \emph{fitness} und \emph{action set size} Wert pro Aktualisierung beeinflusst.TODO
Auch dieser Parameter ist szenariospezifisch, über die konkrete Begründung kann nur spekuliert werden, die Schwierigkeit des Szenarios 
TODO

Vergleichende Tests (siehe Abbildung~\ref{pillar_learning_rate_quality:fig} mit niedrigerem bzw. höherem Wert haben zu einer etwas schlechteren Qualität geführt. TODO

\begin{figure}[htbp]
\centerline{	
\includegraphics{pillar_learning_rate_quality.eps}
}
\caption[Auswirkung des Parameters \emph{learning rate} $\beta$ auf Qualität (Säulenszenario)] {Auswirkung des Parameters \emph{learning rate} $\beta$ auf die Qualität im Säulenszenario, zufälliger Bewegung des Zielobjekts, 8 Agenten mit SXCS Algorithmus}
\label{pillar_learning_rate_quality:fig}
\end{figure}



\section{Parameter \emph{reward prediction init} $p_{i}$}\label{sec:prediction_init}

In der Literatur werden Werte nahe Null bzw. 1\% von \(\rho\) als Initialisierung für den \emph{reward prediction} Wert eines \emph{classifiers} angegeben. Im in dieser Arbeit untersuchten Fall, bei dem die Agenten nur begrenzte Sensorfähigkeiten besitzen, sich auf einem Torus frei bewegen können und keine festen Pfade suchen müssen, ist zu erwarten, dass sich die \emph{reward prediction} Werte der einzelnen \emph{classifier} untereinander wenig unterscheiden, während sie beispielsweise bei statischen Szenarien gegen feste, stark unterschiedliche Werte konvergieren. Beispielsweise im Einführungsbeispiel in Abbildung~\ref{simple_scenario_multistep:fig} würden die \emph{reward prediction} Werte der \emph{classifier} b), c), e) und g) eher gegen 1 und die der restlichen \emph{classifier} gegen 0 streben.\\
Welchen Wert man für \(p_{i}\) nun als Durchschnittswert wählt, hängt vom jeweiligen Szenario ab. Beispielsweise würde ein Überwachungsszenario auf einem sehr größeren Torus mit relativ wenigen Agenten würde zu einem niedrigeren Durchschnittswert für die \emph{reward prediction} Variable führen und umgekehrt.\\
Einfache Idee ist deshalb, auszunutzen, dass im jeweiligen \emph{classifier set} bereits die Information enthalten ist, was der Durchschnittswert für das aktuelle Szenario ist, nämlich der Durchschnittswert aller \emph{reward prediction} Werte. Dies kann man noch dadurch erweitern, dass man bei der Durchschnittsbildung nur solche \emph{classifier} miteinbezieht, welche einen ausreichend großen \emph{experience} Wert besitzen.\\

Tests haben gezeigt, dass dadurch ein deutlich schnelleres Konvergenzverhalten erreicht werden konnte

TODO Test

TODO raus unten
Wählt man einen Wert, der näher am Durchschnitt der \emph{reward prediction} Werte der \emph{classifier} liegt, die sich in den besten Lösungen am Ende eines Testdurchlaufs befinden, so ist zu erwarten, dass die Anzahl der benötigten Aktualisierungen des \emph{reward prediction} Werts geringer ausfällt, das System also schneller konvergiert. Diese Überlegung wird bestätigt durch entsprechende Tests (siehe~\ref{pillar_lcs_prediction_init_quality:fig}).\\
Wir setzen somit für SXCS den Parameter auf \(p_{i} = 1.0\).\\
Zu beachten ist, dass diese Überlegung primär deswegen gilt, weil die 


TODO Standardverfahren?

\begin{figure}[htbp]
\centerline{	
\includegraphics{pillar_lcs_prediction_init_quality.eps}
}
\caption[Auswirkung des Parameters \emph{reward prediction init} $p_{i}$ auf Qualität (Säulenszenario)] {Darstellung Auswirkung des Parameters \emph{reward prediction init} $p_{i}$ auf die Qualität im Säulenszenario, zufälliger Bewegung des Zielobjekts, 8 Agenten mit SXCS Algorithmus}
\label{pillar_lcs_prediction_init_quality:fig}
\end{figure}

\section{Zufällige Initialisierung der \emph{classifier set} Liste}\label{sec:random_init}

Normalerweise werden XCS Systeme mit leeren \emph{classifier set} Listen initialisiert, als Option wird jedoch auch eine zufällige Initialisierung erwähnt~(\cite{Butz2006}), bei der zu Beginn die \emph{classifier set} Liste mit mehreren \emph{classifiers} mit zufälligen \emph{action} Werten und \emph{condition} Vektoren gefüllt wird.\\
Tests haben gezeigt (siehe Tabelle~\ref{table:lcs_initialization}), dass dadurch minimal bessere Ergebnisse erzielt werden, allerdings nur in Szenarien mit ausreichender Schrittzahl (\(>100\)). Dies lässt sich darauf zurückführen, dass  anfänglich gefüllte \emph{classifier set} Listen die \emph{matchSet} Listen relativ groß lassen werden, somit die Auswirkungen anfänglichen Lernens geringer ausfallen und sich die Agenten eher wie sich zufällig bewegende Agenten verhalten. Da hier durchgeführten Tests über 500 bzw. 2000 Schritte laufen, sollen somit die \emph{classifier set} Listen mit zufällig generierten \emph{classifiers} gefüllt werden.

\begin{table}[ht]
\caption{Vergleichende Tests für den den Start mit und ohne zufällig gefüllten \emph{classifier set} Listen}
\centering
\begin{tabular}{c c c c c}
\hline
Algorithmus & Agentenzahl & Schrittzahl & Abdeckung & Qualität \\ [0.5ex]
\hline
Zufälliger Agent & 8 & 500 & 60.64\% & 61.54\% \\
Multistep & 8 & 500 & 60.64\% & 61.54\% \\
LCS & 8 & 500 & 60.64\% & 61.54\% \\
NewLCS & 8 & 500 & 60.64\% & 61.54\% \\
Zufälliges Szenario  & 8 & 500 & 60.64\% & 61.54\% \\
Säulenszenario & 8 & 100 & 1.0\% & 1.0\% \\
LCS Ohne Drehung & 8 & 2000 & 1.0\% & 1.0\% \\ [0.5ex]

LCS Mit Drehung & 8 & 100 & 1.0\% & 1.0\% \\
LCS Mit Drehung & 8 & 500 & 1.0\% & 1.0\% \\
LCS Mit Drehung & 8 & 2000 & 1.0\% & 1.0\% \\ [0.5ex]

Zufälliger Agent & 12 & 500 & 76.03\% & 76.59\% \\
Einfacher Agent & 12 & 500 & 67.30\% & 96.86\% \\
Intelligenter Agent & 12 & 500 & 86.85\% & 95.08\% \\ [0.5ex]

LCS Ohne Drehung & 12 & 100 & 1.0\% & 1.0\% \\
LCS Ohne Drehung & 12 & 500 & 1.0\% & 1.0\% \\
LCS Ohne Drehung & 12 & 2000 & 1.0\% & 1.0\% \\ [0.5ex]

LCS Mit Drehung & 12 & 100 & 1.0\% & 1.0\% \\
LCS Mit Drehung & 12 & 500 & 1.0\% & 1.0\% \\
LCS Mit Drehung & 12 & 2000 & 1.0\% & 1.0\% \\ [0.5ex]

\hline
\end{tabular}
\label{table:lcs_initialization}
\end{table}


\section{Übersicht über alle Parameterwerte}
\begin{table}[ht]
\caption{Verwendete Parameter (soweit nicht anders angegeben) und Standardparameter, TODO englisch/deutsch}
\centering
\begin{tabular}{c c c}
\hline\hline
Parameter & Wert & Standardwert (siehe~\cite{butz01algorithmic})\\ [0.5ex]
\hline
Max population \(N\) & \textbf{128} (siehe Kapitel~\ref{sec:max_population_parameter})\\
Max value \(\rho\) & \textbf{1.0} (siehe Kapitel~\ref{sec:maximalwert_rho}) & [10000]\\
Fraction mean fitness \(\delta\) & 0.1 & [0.1]\\
Deletion threshold \(\theta_{\mathrm{del}}\) & 20.0 & [\(\sim\) 20.0]\\
Subsumption threshold \(\theta_{\mathrm{sub}}\) & 20.0 & [20.0+]\\
Covering \(\#\) probability \(P_{\#}\) & 0.5 & [\(\sim\) 0.33]\\
GAthreshold \(\theta_{\mathrm{GA}}\) & 25.0 & [25-50]\\
Mutation probability \(\mu\) & \(0.05\) & [0.01-0.05]\\
Prediction error reduction & 0.25 & [0.25]\\
Fitness reduction & \(0.1\) & [0.1]\\

Reward prediction init \(p_{i}\) & \textbf{0.5, 1.0} (siehe~\ref{sec:prediction_init}) & [\(\sim\) 0]\\
Prediction error init \(\epsilon_{i}\) & 0.0 & [0.0]\\
Fitness init \(F_{i}\) & \(0.01\) &  [0.01]\\
Condition vector & \textbf{zufällig} (siehe Kapitel~\ref{sec:random_init}) &  [zufällig oder leer]\\
Numerosity & 1 & [1]\\
Experience & 0 & [0]\\

Accuracy equality \(\epsilon_{0}\) & \textbf{0.05} & [\emph{1\% des größten Werts}]\\
Accuracy calculation \(\alpha\) & 0.1 & [0.1]\\
Accuracy power \(\nu\) & 5.0 & [5.0]\\
Reward prediction discount \(\gamma\) & 0.71 & [0.71]\\

Learning rate \(\beta\) & \textbf{0.01} (siehe~\ref{sec:learnrate_parameter}) & [0.1-0.2]\\

exploration probability & 0.5 (siehe~\ref{subsummation:sec}) & [\(\sim\) 0.5]\\ [0.5ex]

\hline
\end{tabular}
\label{table:lcs_parameter}
\end{table}




