\section{Beschreibung und Analyse der XCS Parameter}\label{cha:parameter}

Die Einstellungen der XCS Parameter der durchgeführten Experimente entsprechen weitgehend den Vorschlägen in~\cite{butz01algorithmic} ("`Commonly Used Parameter Settings"'). Eine Auflistung findet sich in Tabelle~\ref{table:lcs_parameter}. Nachstehend werden Parameter besprochen, die entweder in der Empfehlung offen gelassen sind, also klar vom jeweiligen Szenario abhängen, und solche, bei denen von der Empfehlung abgewichen wurde. Es wurden viele weitere Veränderungen getestet, in den meisten Fällen war die Standardeinstellung jedoch passend.\\

Liegt beim Test die erreichte Qualität unter der des zufälligen Algorithmus, ist beim Vergleich der Parameterwerte Vorsicht angebracht. Die Ursache für die Verbesserung kann sein, dass der Algorithmus nicht besser lernt, sondern sich umgekehrt eher wie der zufällige Algorithmus verhält. Deswegen ist stets der Vergleich mit der Qualität des sich zufällig bewegenden Algorithmus anzugeben.\\

Anzumerken sei, dass alle Tests jeweils mit den in Tabelle~\ref{table:lcs_parameter} angegebenen Parameterwerten durchgeführt wurden und bei jedem Test jeweils nur der zu untersuchende Wert verändert wurde. Mit dem Ziel, synchronisierte und vergleichbare Daten zu haben, wurden die Tests in mehreren Etappen durchgeführt. Damit entsprechen die hier aufgeführten Testergebnisse nur den endgültigen Ergebnissen. Der hohe Aufwand dieses Kapitels war notwendig, da der Unterschied zwischen den Qualitäten der verschiedenen Algorithmen eher gering war und keine Vergleichsarbeiten mit der hier verwendeten Problemstellung existieren.


\subsection{Parameter \emph{max population N}}\label{sec:max_population_parameter}

Der Wert von \emph{max population N} bezeichnet die maximalen Größe der \emph{classifier set} Liste. Nach~\cite{butz01algorithmic} sollte \(N\) so groß gewählt werden, dass \emph{covering} nur zu Beginn eines Durchlaufs stattfindet, also die Anzahl der neuerstellten \emph{classifier} gegen Null geht. In Abbildung~\ref{neuerstellte_classifier_maxpop:fig} ist dies für das angegebene Szenario ab einer Populationsgröße von 256 erfüllt.

\begin{figure}[htbp]
\centerline{	
\includegraphics{neuerstellte_classifier_maxpop.eps}
}
\caption[Auswirkung der maximalen Populationsgröße auf die Anzahl der \emph{classifier} die durch \emph{covering} neuerstellt werden (Säulenszenario)]{Auswirkung der maximalen Populationsgröße auf die Anzahl der \emph{classifier} die durch \emph{covering} neuerstellt werden (Säulenszenario, Zielobjekt mit einfacher Richtungsänderung, Geschwindigkeit 1, Agenten mit SXCS)}
\label{neuerstellte_classifier_maxpop:fig}
\end{figure}

Bei der Wahl eines geeigneten Werts spielen außerdem die Konvergenzgeschwindigkeit und die Laufzeit eine Rolle. Einen allgemein besten Wert für \(N\) gibt es nicht, denn er hängt insbesondere von der durch das Szenario und der durch die Länge des \emph{condition} Vektors gegebenen Möglichkeiten ab. Wesentlichen Einfluss auf die Zahl der Möglichkeiten ist, wieviele \emph{classifier} mit verschiedenen \emph{condition} Vektoren und verschiedenem \emph{action} Wert in der \emph{covering} Funktion konstruiert werden können. Würde man beispielsweise weitere Zielobjekte auf das Feld setzen, könnten eine Reihe weiterer Situationen auftreten. So könnten z.B. Zielobjekte in zwei unterschiedlichen Richtungen in Sichtweite eines Agenten kommen. Selbiges gilt für das Szenario ohne Hindernisse, hier fällt eine ganze Anzahl von Möglichkeiten heraus, was man in Abbildung~\ref{neuerstellte_classifier_maxpop_empty:fig} als Vergleich sehen kann.\\

\begin{figure}[htbp]
\centerline{	
\includegraphics{neuerstellte_classifier_maxpop_empty.eps}
}
\caption[Auswirkung der maximalen Populationsgröße auf die Anzahl der \emph{classifier} die durch \emph{covering} neuerstellt werden (leeres Szenario)]{Auswirkung der maximalen Populationsgröße auf die Anzahl der \emph{classifier} die durch \emph{covering} neuerstellt werden (leeres Szenario ohne Hindernisse, Zielobjekt mit einfacher Richtungsänderung, Geschwindigkeit 1, Agenten mit SXCS)}
\label{neuerstellte_classifier_maxpop_empty:fig}
\end{figure}



Für den Overhead (d.h. die Zeit, die 8 Agenten mit zufälliger Bewegung benötigen) ergab sich eine mittlere Laufzeit von \(1,67\)s pro Experiment bei 500 Schritten (bzw. \(6,50\)s bei 2000 Schritten), was die anfängliche Stagnation bis \(N = 32\) erklärt. Zieht man diesen von den Messwerten (siehe Abbildung~\ref{empty_grid_time_maxpop:fig}) ab, erhält man im betrachteten Wertebereich einen nahezu linearen Verlauf (siehe Abbildung~\ref{linear_pop_time:fig}, ab \(N > 128\)). Der fallende Verlauf bis 128 erklärt sich durch den Overhead des XCS Algorithmus selbst.\\

Die wichtigsten \emph{classifier} sind mit Populationsgröße 256 (bzw. 128 im leeren Szenario) bereits abgedeckt. Eine Erhöhung der Populationsgröße führt daher lediglich zu einer Erhöhung der Laufzeit. Da den Agenten das Szenario unbekannt ist, soll für alle Szenarien der selbe Wert benutzt werden soll. Alles in allem scheint somit \(N = 256\) die schnellste Parametereinstellung zu sein, die gleichzeitig auch ausreichend Platz für \emph{classifier} für die Abdeckung der Möglichkeiten der betrachteten Szenarien bietet.\\

Die Tests liefen auf einem T7500, \(2,2\) GHz in einem einzelnen Thread. Als Vergleich hierzu wurde auch der Einfluss der Torusgröße auf die Laufzeit betrachtet, wie in Abbildung~\ref{time_map_size_correlation:fig} zu sehen, ist der Einfluss auf die Laufzeit im getesteten Bereich (16x16 bis 64x64) ohne Bedeutung.\\


\begin{figure}[htbp]
\centerline{	
\includegraphics{time_map_size_correlation.eps}
}
\caption[Auswirkung der Torusgröße auf die Laufzeit (leeres Szenario)] {Darstellung der Auswirkung der Torusgröße auf die Laufzeit im leeren Szenario, zufälliger Bewegung des Zielobjekts, Geschwindigkeit 1, sich zufällig bewegenden Agenten}
\label{time_map_size_correlation:fig}
\end{figure}

\begin{figure}[htbp]
\centerline{	
\includegraphics{empty_grid_time_maxpop.eps}
}
\caption[Auswirkung des Parameters \emph{max population N} auf Laufzeit (leeres Szenario)] {Darstellung der Auswirkung des Parameters \emph{max population N} auf die Laufzeit im leeren Szenario, zufälliger Bewegung des Zielobjekts, Geschwindigkeit 1, Agenten mit SXCS Algorithmus}
\label{empty_grid_time_maxpop:fig}
\end{figure}

\begin{figure}[htbp]
\centerline{	
\includegraphics{linear_pop_time.eps}
}
\caption[Verhältnis Laufzeit zu \emph{max population N} (leeres Szenario)] {Darstellung der Auswirkung des Parameters \emph{max population N} auf das Verhältnis der Laufzeit zu \(N\) im leeren Szenario, zufälliger Bewegung des Zielobjekts, Geschwindigkeit 1, Agenten mit SXCS Algorithmus}
\label{linear_pop_time:fig}
\end{figure}


\subsection{Zufällige Initialisierung der \emph{classifier set} Liste}\label{sec:random_init}

Normalerweise werden XCS Systeme mit leeren \emph{classifier set} Listen initialisiert, als Option wird jedoch auch eine zufällige Initialisierung erwähnt \cite{Butz2006}, bei der zu Beginn die \emph{classifier set} Liste mit mehreren \emph{classifier} mit zufälligen \emph{action} Werten und \emph{condition} Vektoren gefüllt wird. Dort wird aber auch angemerkt, dass sich beide Varianten in ihrer Qualität nur wenig unterscheiden. Da zum einen gewisser Zeitaufwand nötig ist, die Liste zu füllen und zum anderen nicht sichergestellt ist, dass die generierten \emph{classifier} in dem jeweiligen Szenario überhaupt aktiviert werden können, scheint es sinnvoll zu sein mit einer leeren \emph{classifier set} Liste zu starten.\\

Dies bestätigen auch Tests, in denen man die Anzahl durch \emph{covering} neu erstellter \emph{classifier} ohne zufällige Initialisierung der \emph{classifier set} Liste (Abbildung~\ref{neuerstellte_classifier_maxpop_not_initialized:fig}) mit der Anzahl mit Initialisierung (Abbildung~\ref{neuerstellte_classifier_maxpop:fig}) verglichen hat. Hier erkennt man, dass zwar anfangs weniger neue \emph{classifier} generiert werden müssen, umgekehrt aber einige der generierten \emph{classifier} kaum mehr aus dem \emph{classifier set} zu bekommen sind. Beispielsweise stagniert die Anzahl der generierten \emph{classifier} im Fall mit vorinitialisierter \emph{classifier set} Liste bei einer Populationsgröße von 128 bei etwa 2000 pro 500 Schritte und 8 Agenten, während sie im Fall ohne Initialisierung gegen 0 geht.\\

Entsprechend müssen im zweiten Fall mit vorinitialisierter Liste die überflüssigen \emph{classifier} erst mühsam erkannt und entfernt werden, was im Grunde die Populationsgröße bis dahin verringert. Es müsste also ein größeres \(N\) benutzt werden, was wiederum die Laufzeit erhöht. Aus diesen Gründen sollen alle Agenten mit leerer Liste starten.

\begin{figure}[htbp]
\centerline{	
\includegraphics{neuerstellte_classifier_maxpop_not_initialized.eps}
}
\caption[Auswirkung der maximalen Populationsgröße auf die Anzahl der \emph{classifier}, die durch \emph{covering} neuerstellt werden (Säulenszenario, ohne Initialisierung der \emph{classifier set} Liste)]{Auswirkung der maximalen Populationsgröße auf die Anzahl der \emph{classifier}, die durch \emph{covering} neuerstellt werden (Säulenszenario, Zielobjekt mit einfacher Richtungsänderung, Geschwindigkeit 1, Agenten mit SXCS, ohne Initialisierung der \emph{classifier set} Liste)}
\label{neuerstellte_classifier_maxpop_not_initialized:fig}
\end{figure}


\subsection{Parameter \emph{reward prediction discount} $\gamma$}

In der Literatur in~\cite{butz01algorithmic} wird ein Standardwert von \(0,71\) genannt, es seien je nach Szenario aber auch größere und kleinere Werte möglich. 
Ein höherer Wert für \(\gamma\) bedeutet, dass die Höhe des Werts, der über \emph{maxPrediction} weitergegeben wird, mit zeitlichem Abstand zur ursprünglichen Bewertung mit einem \emph{base reward}, weniger schnell abfällt, wodurch eine längere Verkettung von \emph{base reward} Werten möglich ist. Umgekehrt führen zu hohe Werte für \(\gamma\) zu der positiven Bewertung von \emph{classifier} die am Erfolg gar nicht beteiligt waren, was sich negativ auf die Qualität auswirken kann.\\

Abbildung~\ref{prediction_discount:fig} zeigt einen Vergleich der Qualität bei unterschiedlichen Werten für \(\gamma\) beim XCS Algorithmus im Säulenszenario. "`Intelligent"', "`Einfache Richtungsänderung"' und "`Geschwindigkeit"' beziehen sich jeweils auf die Eigenschaften des Zielobjekts. Ein konkretes Muster ist nicht zu erkennen und die Fluktuationen sind minimal, weshalb wie vorgeschlagen hier jeweils \(\gamma = 0,71\) verwendet wird. Diese Tatsache ist ein Hinweis darauf, dass die Weitergabe des \emph{base reward} grundsätzlich erfolgen sollte (Abfall der Qualitätsdifferenz auf 0), jedoch sonst keinen Einfluss hat, also wahrscheinlich keine zusammenhänhenden Aktions-Ketten gebildet werden. Diese Tatsache unterstreicht auch, dass im Überwachungsszenario das Finden von "`Wegen"' (wie beim einführenden Beispiel zum \emph{multi step} Verfahren in Kapitel~\ref{multi_step_intro:sec}) nicht zum Erfolg führt. Mit einer Erweiterung der Sensoren, prägnanteren Hindernissstrukturen und Aufenthaltswahrscheinlichkeiten des Zielobjekts auf dem Torus mit hoher Varianz würde dies wahrscheinlich anders aussehen.

\begin{figure}[htbp]
\centerline{	
\includegraphics{prediction_discount.eps}
}
\caption[Auswirkung verschiedener \emph{reward prediction discount} $\gamma$ Werte auf die Qualität]{Auswirkung verschiedener \emph{reward prediction discount} $\gamma$ Werte auf die Qualität (Säulenszenario, Agenten mit XCS, 2000 Schritte)}
\label{prediction_discount:fig}
\end{figure}



\subsection{Parameter Lernrate $\beta$}\label{sec:learnrate_parameter}

Die Lernrate \(\beta\) hatte in den Tests kaum Auswirkungen auf die Qualität. Da eine ausreichend hohe Populationsgröße gewählt wurde (es werden nicht dauernd neue \emph{classifier} erstellt) und die Schrittzahl groß genug war, pendelten sich die entsprechenden Werte ein. Die Lernrate bestimmt u.a., wie stark ein ermittelter \emph{reward} Wert den \emph{reward prediction}, \emph{reward prediction error} und \emph{fitness} Wert bei jeder Aktualisierung beeinflusst.\\ 

Vergleichende Tests (siehe Abbildung~\ref{pillar_learning_rate_quality:fig}) lassen ab etwa \(\beta = 0,01\) einen leichten Abwärtstrend bei größeren Werten feststellen, bei kleineren Werten für \(\beta\) gibt es jedoch keine signifikante Unterschiede. Nur im schwierigen Szenario ist ein Unterschied zu bemerken (siehe Abbildung~\ref{difficult_learning_rate_quality:fig}), dort soll \(0,1\) als Lernrate \(\beta\) gewählt werden. XCS hat hier Probleme das Gelernte zu behalten, verlernt also, Öffnungen zu finden. SXCS profitiert umgekehrt von einer großen Lernrate. Durch die direkte Verknüpfung der \emph{classifier} wird der Weg durch die Öffnungen beim Erreichen des Ziels belohnt. Weiter Aufschluss gibt die Betrachtung des laufenden Durchschnitts der Qualität des Algorithmus (siehe Abbildung~\ref{plot_100_goal_agent_observed-16-03-09--15-07-16-989:fig}). SXCS scheint mit \(\beta = 0,1\) einen stabilen Wert erreicht zu haben, während SXCS mit \(\beta = 0,001\) nicht viel besser abschneidet als der Agent mit zufälliger Bewegung. XCS scheint dagegen zu Beginn mit SXCS mit \(\beta = 0,1\) mithalten zu können. Ab etwa der Hälfte fällt es jedoch sogar unter die Qualität des Algorithmus mit zufälliger Bewegung, scheint also konkret etwas falsches gelernt zu haben. TODO, neues Bild mit random

\begin{figure}[htbp]
\centerline{	
\includegraphics{lernrate_beta.eps}
}
\caption[Auswirkung des Parameters \emph{learning rate} $\beta$ auf Qualität (Säulenszenario)] {Auswirkung des Parameters \emph{learning rate} $\beta$ auf die Qualität im Säulenszenario, intelligente Bewegung des Zielobjekts, Geschwindigkeit 1, Agenten mit SXCS Algorithmus, 2000 Schritte}
\label{pillar_learning_rate_quality:fig}
\end{figure}

\begin{figure}[htbp]
\centerline{	
\includegraphics{difficult_learnrate.eps}
}
\caption[Auswirkung des Parameters \emph{learning rate} $\beta$ auf Qualität (Schwieriges Szenario)] {Auswirkung des Parameters \emph{learning rate} $\beta$ auf die Qualität im schwierigen Szenario, Bewegung des Zielobjekts ohne Richtungsänderung, Geschwindigkeit 2, Agenten mit SXCS Algorithmus, 2000 Schritte}
\label{difficult_learning_rate_quality:fig}
\end{figure}

\begin{figure}[htbp]
\centerline{	
\includegraphics{plot_100_goal_agent_observed-16-03-09--15-07-16-989.eps}
}
\caption[Zeitlicher Verlauf des gleitenden Durchschnitts der Qualität (schwieriges Szenario, SXCS und XCS mit Lernrate $0,1$)]{Zeitlicher Verlauf des gleitenden Durchschnitts der Qualität (schwieriges Szenario, Bewegung des Zielobjekts ohne Richtungsänderung, Geschwindigkeit 2, SXCS und XCS mit Lernrate $0,1$, 2000 Schritte)}
\label{plot_100_goal_agent_observed-16-03-09--15-07-16-989:fig}
\end{figure}


\subsection{Parameter \emph{accuracy equality} $\epsilon_{0}$}\label{epsilon0:sec}

Der Parameter \(\epsilon_{0}\) gibt an, unter welchem \emph{reward prediction error} Wert ein \emph{classifier} als exakt gilt (und als \emph{subsumer} auftreten kann, siehe Kapitel~\ref{subsummation:sec}) und wie stark dieser Wert in die Berechnung der \emph{fitness} einfließt. In der Literatur~\cite{butz01algorithmic} wird als Regel genannt, dass der Wert auf etwa 1\% des Maximalwerts des \emph{base reward} Werts (\(\rho\)) gesetzt werden soll, welcher beliebig wählbar ist und lediglich ästhetische Auswirkungen hat. Somit wird dieser auf \(1,0\) gesetzt und \(\epsilon_{0}\) auf \(0,01\).


\subsection{Parameter \emph{tournament factor p}}\label{tournament_factor_test:sec}

In Abbildung~\ref{test_tournament_selection_direction_1:fig} und Abbildung~\ref{test_tournament_selection_direction_2:fig} sind die Ergebnisse im Säulenszenario mit einem Zielobjekt mit einfacher Richtungsänderung, einmal mit Geschwindigkeit 1, das andere Mal mit Geschwindigkeit 2, dargestellt. Was den \emph{tournament factor p} betrifft, ist für XCS das Maximum bei \(0,88\) (Geschwindigkeit 1) bzw. \emph{0,80} (Geschwindigkeit 2).\\

Bei SXCS ist deutlich zu sehen, dass eine andauernde \emph{exploit} Phase bei beiden Geschwindigkeiten im Vergleich zu abwechselnden \emph{explore}/\emph{exploit} Phasen deutlich benachteiligt ist, teilweise sogar schlechter abschneidet als XCS. Die Maximalwerte bei SXCS liegen im Bereich von \(0,72\) bis \(0,88\) für Geschwindigkeit 1 und mit langsamer Steigung bei \(0,92\) für Geschwindigkeit 2. Ein sinnvoller Kompromiss erscheint hier deshalb \(0,84\) als Wert für den \emph{tournament factor p} zu benutzen.

\begin{figure}[htbp]
\centerline{	
\includegraphics{test_tournament_selection_direction_1.eps}
}
\caption[Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (Zielobjekt mit einfacher Richtungsänderung, Geschwindigkeit 1)]{Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (Zielobjekt mit einfacher Richtungsänderung, Geschwindigkeit 2, Säulenszenario, 2000 Schritte)}
\label{test_tournament_selection_direction_1:fig}
\end{figure}

\begin{figure}[htbp]
\centerline{	
\includegraphics{test_tournament_selection_direction_2.eps}
}
\caption[Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (Zielobjekt mit einfacher Richtungsänderung, Geschwindigkeit 1)]{Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (Zielobjekt mit einfacher Richtungsänderung, Geschwindigkeit 2, Säulenszenario, 2000 Schritte)}
\label{test_tournament_selection_direction_2:fig}
\end{figure}

Im Falle eines Zielobjekts mit intelligenter Bewegung (Abbildung~\ref{test_tournament_selection_intelligent_1:fig} mit Geschwindigkeit 1 und Abbildung~\ref{test_tournament_selection_intelligent_2:fig} mit Geschwindigkeit 2) fällt direkt ins Auge, dass eine abwechselnde \emph{explore}/\emph{exploit} Phase nicht vorteilhaft für einen SXCS Agenten ist. XCS erreicht ein ziemlich konstantes Ergebnis im Bereich von \(0,76\) bis \(0,92\), während SXCS mit andauernder \emph{exploit} Phase bei einem Wert von um die \(0,80\) den Maximalwert besitzt. Dass beim XCS Algorithmus im Fall mit Geschwindigkeit 2 bei einem Wert von \(p = 1.0\), also der \emph{best selection} Auswahlart, ein etwas besseres Ergebnis erzielt wird, erstaunt. Da der Wert während des Laufs aber nicht angepasst wird, besteht keine Möglichkeit, dies auszunutzen und gleichzeitig bei allen anderen Tests gut abzuschneiden.

\begin{figure}[htbp]
\centerline{	
\includegraphics{test_tournament_selection_intelligent_1.eps}
}
\caption[Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (intelligentes Zielobjekt, Geschwindigkeit 1)]{Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (intelligentes Zielobjekt, Geschwindigkeit 1, Säulenszenario, 2000 Schritte)}
\label{test_tournament_selection_intelligent_1:fig}
\end{figure}

\begin{figure}[htbp]
\centerline{	
\includegraphics{test_tournament_selection_intelligent_2.eps}
}
\caption[Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (intelligentes Zielobjekt, Geschwindigkeit 2)]{Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (intelligentes Zielobjekt, Geschwindigkeit 2, Säulenszenario, 2000 Schritte)}
\label{test_tournament_selection_intelligent_2:fig}
\end{figure}

Insgesamt bestätigt die Untersuchung also, dass \(p = 0,84\) für diese Szenarien sinnvoll ist und somit die beste Aktion also mit \(84\%\) Wahrscheinlichkeit, die zweitbeste mit ca. \((1,0-p)p \approx 13\%\) Wahrscheinlichkeit, die drittbeste mit ca. \((1,0-p)^{2}p \approx 2\%\) Wahrscheinlichkeit und die schlechteste Aktion mit ca. \((1,0-p)^{3}p \approx 1\%\) Wahrscheinlichkeit gewählt werden.\\

Außerdem kann man erkennen, dass bei einem sich intelligent verhaltenden Zielobjekt eine andauernde \emph{exploit} Phase die beste Wahl ist. Dies wird in Kapitel~\ref{test_auswahlarten:sec} relevant und dort auch näher diskutiert.\\

Anzumerken ist weiterhin, dass, weil nicht eine andauernde \emph{exploit} Phase mit \emph{best selection} gewählt wurde, die hier benutzten auf XCS basierenden Agenten nicht die Qualität von Heuristiken erreichen können. Kann beispielsweise die einfache Heuristik fast problemlos ein Zielobjekt, was sich mit einer Geschwindigkeit von \(1,0\) bewegt,  unendlich lange verfolgen, bricht ein XCS Algorithmus diese Verfolgung in jedem Schritt mit einer Wahrscheinlichkeit von mindestens \(100\% - 84\% = 16\%\) ab.\\


\subsection{Übersicht über alle Parameterwerte}

\begin{table}[ht]
\caption{Verwendete Parameter (soweit nicht anders angegeben) und Standardparameter}
\centering
\begin{tabular}{c c c}
\hline\hline
Parameter & Wert & Standardwert~\cite{butz01algorithmic}\\ [0.5ex]
\hline
max population \(N\) & \textbf{256} (siehe Kapitel~\ref{sec:max_population_parameter}) & [\emph{je nach Szenario}]\\
max value \(\rho\) & \textbf{1,0} (siehe Kapitel~\ref{epsilon0:sec}) & [10000]\\
fraction mean fitness \(\delta\) & 0,1 & [0,1]\\
deletion threshold \(\theta_{\mathrm{del}}\) & 20,0 & [\(\sim\) 20,0]\\
subsumption threshold \(\theta_{\mathrm{sub}}\) & 20,0 & [20,0+]\\
covering \(\#\) probability \(P_{\#}\) & 0,33 & [\(\sim\) 0,33]\\
GA threshold \(\theta_{\mathrm{GA}}\) & 25 & [25-50]\\
mutation probability \(\mu\) & \(0,05\) & [0,01-0,05]\\
prediction error reduction & 0,25 & [0,25]\\
fitness reduction & \(0,1\) & [0,1]\\

reward prediction init \(p_{i}\) & 0,01 & [\(\sim\) 0]\\
prediction error init \(\epsilon_{i}\) & 0,0 & [0,0]\\
fitness init \(F_{i}\) & \(0,01\) &  [0,01]\\
condition vector & \textbf{leer} (siehe Kapitel~\ref{sec:random_init}) &  [\emph{zufällig oder leer}]\\
numerosity & 1 & [1]\\
experience & 0 & [0]\\

accuracy equality \(\epsilon_{0}\) & \textbf{0,01} (siehe Kapitel~\ref{epsilon0:sec}) & [\emph{1\% des größten Werts}]\\
accuracy calculation \(\alpha\) & 0,1 & [0,1]\\
accuracy power \(\nu\) & 5,0 & [5,0]\\
reward prediction discount \(\gamma\) & 0,71 & [0,71]\\

learning rate \(\beta\) & \textbf{0,001 - 0,01} (siehe Kapitel~\ref{sec:learnrate_parameter}) & [0,1-0,2]\\

exploration probability & 0,5 (siehe Kapitel~\ref{subsummation:sec}) & [\(\sim\) 0,5]\\
tournament factor & 0,84 (siehe Kapitel~\ref{tournament_factor_test:sec}) & [-]\\ [0.5ex]

\hline
\end{tabular}
\label{table:lcs_parameter}
\end{table}
