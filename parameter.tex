\section{Beschreibung und Analyse der XCS Parameter}\label{cha:parameter}

Die Einstellungen der XCS Parameter der durchgeführten Experimente entsprechen weitgehend den Vorschlägen in~\cite{butz01algorithmic} ("`Commonly Used Parameter Settings"'). Eine Auflistung findet sich in Tabelle~\ref{table:lcs_parameter}. Im Folgenden sollen Parameter besprochen werden, die entweder in der Empfehlung offen gelassen sind, also klar vom jeweiligen Szenario abhängen, und solche, bei denen von der Empfehlung abgewichen wurde. Es wurden viele weitere Veränderungen getestet, in den meisten Fällen war die Standardeinstellung jedoch passend.\\

Mitunter führen andere Parametereinstellungen auch zu wesentlich besseren Ergebnissen. Dies muss man aber vorsichtig bewerten, wenn die erreichte Qualität unter der des zufälligen Algorithmus liegt, da eine Auswirkung sein kann, dass der Algorithmus nicht besser lernt, sondern sich umgekehrt eher wie der zufällige Algorithmus verhält. Ein Vergleich mit der Qualität des zufälligen Algorithmus wird deswegen jeweils immer angegeben.\\

Anzumerken sei, dass alle Tests jeweils mit den in Tabelle~\ref{table:lcs_parameter} angegebenen Parameterwerten durchgeführt wurden und bei jedem Test jeweils nur der zu untersuchende Wert verändert wurde. Um synchronisierte und vergleichbare Daten zu haben, wurden die Tests deshalb in vielen Etappen durchgeführt, die angegebenen Testergebnisse entsprechen jeweils nur den endgültigen Ergebnissen.\\


\subsection{Parameter \emph{max population N}}\label{sec:max_population_parameter}

Der Wert von \emph{max population N} bezeichnet die maximalen Größe der \emph{classifier set} Liste. Nach~\cite{butz01algorithmic} sollte \(N\) so groß gewählt werden, dass \emph{covering} nur zu Beginn eines Durchlaufs stattfindet, also die Anzahl der neuerstellten \emph{classifier} gegen Null geht. In Abbildung~\ref{neuerstellte_classifier_maxpop:fig} ist dies für das angegebene Szenario ab einer Populationsgröße von 256 erfüllt.

\begin{figure}[htbp]
\centerline{	
\includegraphics{neuerstellte_classifier_maxpop.eps}
}
\caption[Auswirkung der maximalen Populationsgröße auf die Anzahl der \emph{classifier} die durch \emph{covering} neuerstellt werden (Säulenszenario)]{Auswirkung der maximalen Populationsgröße auf die Anzahl der \emph{classifier} die durch \emph{covering} neuerstellt werden (Säulenszenario, Zielobjekt mit einfacher Richtungsänderung, Geschwindigkeit 1, Agenten mit SXCS)}
\label{neuerstellte_classifier_maxpop:fig}
\end{figure}

Bei der Wahl eines geeigneten Werts spielen außerdem die Konvergenzgeschwindigkeit und die Laufzeit eine Rolle. Einen allgemein besten Wert für \(N\) gibt es nicht, denn er hängt insbesondere von der durch das Szenario und der durch die Länge des \emph{condition} Vektors gegebenen Möglichkeiten ab, also wieviele \emph{classifier} mit verschiedenen \emph{condition} Vektoren und verschiedenem \emph{action} Wert in der \emph{covering} Funktion konstruiert werden können. Würde man beispielsweise weitere Zielobjekte auf das Feld setzen, könnten eine Reihe weiterer Situationen auftreten, beispielsweise könnten Zielobjekte in Sicht in zwei unterschiedlichen Richtungen auftauchen. Selbiges gilt für das Szenario ohne Hindernisse, hier fällt eine ganze Anzahl von Möglichkeiten heraus, was man in Abbildung~\ref{neuerstellte_classifier_maxpop_empty:fig} als Vergleich sehen kann.\\


\begin{figure}[htbp]
\centerline{	
\includegraphics{neuerstellte_classifier_maxpop_empty.eps}
}
\caption[Auswirkung der maximalen Populationsgröße auf die Anzahl der \emph{classifier} die durch \emph{covering} neuerstellt werden (leeres Szenario)]{Auswirkung der maximalen Populationsgröße auf die Anzahl der \emph{classifier} die durch \emph{covering} neuerstellt werden (leeres Szenario ohne Hindernisse, Zielobjekt mit einfacher Richtungsänderung, Geschwindigkeit 1, Agenten mit SXCS)}
\label{neuerstellte_classifier_maxpop_empty:fig}
\end{figure}



Für den Overhead (d.h. die Zeit, die 8 Agenten mit zufälliger Bewegung benötigen) ergab sich eine mittlere Laufzeit von \(1,67\)s pro Experiment bei 500 Schritten (bzw. \(6,50\)s bei 2000 Schritten), was die anfängliche Stagnation bis \(N = 32\) erklärt. Zieht man diesen von den Messwerten (siehe Abbildung~\ref{empty_grid_time_maxpop:fig}) ab, erhält man im betrachteten Wertebereich einen nahezu linearen Verlauf (siehe Abbildung~\ref{linear_pop_time:fig}, ab \(N > 128\)). Der fallende Verlauf bis 128 erklärt sich durch den Overhead des XCS Algorithmus selbst.\\

Da also die wichtigsten \emph{classifier} mit Populationsgröße 256 (bzw. 128 im leeren Szenario) bereits abgedeckt sind, führt eine Erhöhung der Populationsgröße nur zu einer Erhöhung der Laufzeit. Da den Agenten das Szenario unbekannt ist, soll für alle Szenarien der selbe Wert benutzt werden soll. Alles in allem scheint somit \(N = 256\) die schnellste Parametereinstellung zu sein, die gleichzeitig auch ausreichend Platz für \emph{classifier} für die Abdeckung der Möglichkeiten der betrachteten Szenarien bietet.\\

Die Tests liefen auf einem T7500, \(2,2\) GHz in einem einzelnen Thread. Als Vergleich hierzu wurde auch der Einfluss der Kartengröße auf die Laufzeit betrachtet, wie in Abbildung~\ref{time_map_size_correlation:fig} zu sehen, ist der Einfluss auf die Laufzeit im getesteten Bereich (16x16 - 64x64) ohne Bedeutung.\\


\begin{figure}[htbp]
\centerline{	
\includegraphics{time_map_size_correlation.eps}
}
\caption[Auswirkung der Torusgröße auf die Laufzeit (leeres Szenario)] {Darstellung der Auswirkung der Torusgröße auf die Laufzeit im leeren Szenario, zufälliger Bewegung des Zielobjekts, Geschwindigkeit 1, sich zufällig bewegenden Agenten}
\label{time_map_size_correlation:fig}
\end{figure}

\begin{figure}[htbp]
\centerline{	
\includegraphics{empty_grid_time_maxpop.eps}
}
\caption[Auswirkung des Parameters \emph{max population N} auf Laufzeit (leeres Szenario)] {Darstellung der Auswirkung des Parameters \emph{max population N} auf die Laufzeit im leeren Szenario, zufälliger Bewegung des Zielobjekts, Geschwindigkeit 1, Agenten mit SXCS Algorithmus}
\label{empty_grid_time_maxpop:fig}
\end{figure}

\begin{figure}[htbp]
\centerline{	
\includegraphics{linear_pop_time.eps}
}
\caption[Verhältnis Laufzeit zu \emph{max population N} (leeres Szenario)] {Darstellung der Auswirkung des Parameters \emph{max population N} auf das Verhältnis der Laufzeit zu \(N\) im leeren Szenario, zufälliger Bewegung des Zielobjekts, Geschwindigkeit 1, Agenten mit SXCS Algorithmus}
\label{linear_pop_time:fig}
\end{figure}


\subsection{Zufällige Initialisierung der \emph{classifier set} Liste}\label{sec:random_init}

Normalerweise werden XCS Systeme mit leeren \emph{classifier set} Listen initialisiert, als Option wird jedoch auch eine zufällige Initialisierung erwähnt \cite{Butz2006}, bei der zu Beginn die \emph{classifier set} Liste mit mehreren \emph{classifiers} mit zufälligen \emph{action} Werten und \emph{condition} Vektoren gefüllt wird. Dort wird aber auch angemerkt, dass beide Varianten in ihrer Qualität sich nur wenig unterscheiden. Da zum einen gewisser Zeitaufwand nötig ist, die Liste zu füllen und zum anderen nicht sichergestellt ist, dass die generierten \emph{classifier} in dem jeweiligen Szenario überhaupt aktiviert werden können, scheint es sinnvoll zu sein mit einer leeren \emph{classifier set} Liste zu starten.\\

Dies bestätigen auch Tests, vergleicht man die Anzahl durch \emph{covering} neu erstellter \emph{classifier} ohne zufällige Initialisierung der \emph{classifier set} Liste (Abbildung~\ref{neuerstellte_classifier_maxpop_not_initialized:fig}) mit der mit Initialisierung (Abbildung~\ref{neuerstellte_classifier_maxpop:fig}) erkennt man, dass zwar anfangs weniger neue \emph{classifier} generiert werden müssen, umgekehrt aber einige der generierten \emph{classifier} kaum mehr aus dem \emph{classifier set} zu bekommen sind. Beispielsweise stagniert die Anzahl der generierten \emph{classifier} im Fall mit vorinitialisierter \emph{classifier set} Liste bei einer Populationsgröße von 128 bei etwa 2000 pro 500 Schritte und 8 Agenten, während sie im Fall ohne Initialisierung gegen 0 geht.\\

Im zweiten Fall mit vorinitialisierter Liste müssen die überflüssigen \emph{classifier} also erst mühsam erkannt und entfernt werden, was im Grunde die Populationsgröße bis dahin verringert. Es müsste also ein größeres \(N\) benutzt werden, was wiederum die Laufzeit erhöht. Aus diesen Gründen sollen alle Agenten mit leerer Liste starten.

\begin{figure}[htbp]
\centerline{	
\includegraphics{neuerstellte_classifier_maxpop_not_initialized.eps}
}
\caption[Auswirkung der maximalen Populationsgröße auf die Anzahl der \emph{classifier}, die durch \emph{covering} neuerstellt werden (Säulenszenario, ohne Initialisierung der \emph{classifier set} Liste)]{Auswirkung der maximalen Populationsgröße auf die Anzahl der \emph{classifier}, die durch \emph{covering} neuerstellt werden (Säulenszenario, Zielobjekt mit einfacher Richtungsänderung, Geschwindigkeit 1, Agenten mit SXCS, ohne Initialisierung der \emph{classifier set} Liste)}
\label{neuerstellte_classifier_maxpop_not_initialized:fig}
\end{figure}


\subsection{Parameter \emph{reward prediction discount} $\gamma$}

In der Literatur in~\cite{butz01algorithmic} wird ein Standardwert von \(0,71\) genannt, es seien je nach Szenario aber auch größere und kleinere Werte möglich. 
Ein höherer Wert für \(\gamma\) bedeutet, dass die Höhe des Werts, der über \emph{maxPrediction} weitergegeben wird, mit zeitlichem Abstand zur ursprünglichen Bewertung mit einem \emph{reward}, weniger schnell abfällt, wodurch eine längere Verkettung von \emph{reward} Werten möglich ist. Umgekehrt führen zu hohe Werte für \(\gamma\) zu der positiven Bewertung von \emph{classifiers} die am Erfolg gar nicht beteiligt waren, was sich negativ auf die Qualität auswirken kann.\\
Abbildung~\ref{prediction_discount:fig} zeigt einen Vergleich der Qualität bei unterschiedlichen Werten für \(\gamma\) beim XCS Algorithmus im Säulenszenario. Wie vorgeschlagen wird hier jeweils \(\gamma = 0,71\) verwendet werden.


\begin{figure}[htbp]
\centerline{	
\includegraphics{prediction_discount.eps}
}
\caption[Auswirkung verschiedener \emph{prediction discount} $\gamma$ Werte auf die Qualität]{Auswirkung verschiedener \emph{prediction discount} $\gamma$ Werte auf die Qualität (Säulenszenario, Zielobjekt mit einfacher Richtungsänderung und Geschwindigkeit 1, Agenten mit XCS)}
\label{prediction_discount:fig}
\end{figure}



\subsection{Parameter Lernrate $\beta$}\label{sec:learnrate_parameter}

Die Lernrate \(\beta\) hatte in den Tests kaum Auswirkungen auf die Qualität. Da eine ausreichend hohe Populationsgröße gewählt wurde (es werden nicht dauernd neue \emph{classifier} erstellt) und die Schrittzahl groß genug war, pendelten sich die entsprechenden Werte ein. Die Lernrate bestimmt, wie stark ein ermittelter \emph{reward} Wert den \emph{reward prediction}, \emph{reward prediction error}, \emph{fitness} und \emph{action set size} Wert bei jeder Aktualisierung beeinflusst. Vergleichende Tests (siehe Abbildung~\ref{pillar_learning_rate_quality:fig}) lassen einen leichten Abwärtstrend bei größeren Werten feststellen, signifikante Unterschiede, vom zusätzlich dargestellten Extremwert bei \(0,00001\) abgesehen, gibt es aber keine, weshalb die Wahl im Grunde beliebig ist. \\

TODO!
Ein Unterschied ist erst in schwierigen Szenarien zu bemerken (siehe Abbildung~\ref{difficult_learning_rate_quality:fig}), dort soll \(0,001\) als Lernrate \(\beta\) gewählt werden. Der Grund für diesen Unterschied ist schwierig zu erkennen. Nötig war hierzu die Betrachung des laufenden Durchschnitts der Qualität des Algorithmus (siehe Abbildung~\ref{difficult_learning_rate_continous_quality:fig}), bei der beide Varianten im ersten Problem bis 2000 Schritte gleichauf sind, dann die Variante mit vergleichsweise großer Lernrate bei niedrigem Level stehenbleibt. Ein weiterer Test mit einer leicht modifizierten SXCS Version (die Option 

\begin{figure}[htbp]
\centerline{	
\includegraphics{lernrate_beta.eps}
}
\caption[Auswirkung des Parameters \emph{learning rate} $\beta$ auf Qualität (Säulenszenario)] {Auswirkung des Parameters \emph{learning rate} $\beta$ auf die Qualität im Säulenszenario, intelligente Bewegung des Zielobjekts, Agenten mit SXCS Algorithmus, 2000 Schritte}
\label{pillar_learning_rate_quality:fig}
\end{figure}

\begin{figure}[htbp]
\centerline{	
\includegraphics{difficult_learnrate.eps}
}
\caption[Auswirkung des Parameters \emph{learning rate} $\beta$ auf Qualität (Schwieriges Szenario)] {Auswirkung des Parameters \emph{learning rate} $\beta$ auf die Qualität im schwierigen Szenario, Bewegung des Zielobjekts ohne Richtungsänderung, Geschwindigkeit 1, Agenten mit SXCS Algorithmus, 2000 Schritte}
\label{difficult_learning_rate_quality:fig}
\end{figure}



\subsection{Parameter \emph{accuracy equality} $\epsilon_{0}$}\label{epsilon0:sec}

Der Parameter \(\epsilon_{0}\) gibt an, unter welchem \emph{reward prediction error} Wert ein \emph{classifier} als exakt gilt (und als \emph{subsumer} auftreten kann, siehe Kapitel~\ref{subsummation:sec}) und wie stark dieser Wert in die Berechnung der \emph{fitness} einfliesst. In der Literatur~\cite{butz01algorithmic} wird als Regel genannt, dass der Wert auf etwa 1\% des Maximalwerts des \emph{base reward} Werts (\(\rho\)) gesetzt werden soll, welcher beliebig wählbar ist und lediglich ästhetische Auswirkungen hat. Somit wird dieser auf \(1,0\) gesetzt und \(\epsilon_{0}\) auf \(0,01\).

\subsection{Parameter \emph{tournament factor p}}\label{tournament_factor_test:sec}


In Abbildung~\ref{test_tournament_selection_direction_1:fig} und Abbildung~\ref{test_tournament_selection_direction_2:fig} sind die Ergebnisse im Säulenszenario mit einem Zielobjekt mit einfacher Richtungsänderung, einmal mit Geschwindigkeit 1, das andere Mal mit Geschwindigkeit 2, dargestellt. Die Qualitätsdifferenz bezeichnet hier zur besseren Übersicht die Differenz der Qualität des Algorithmus zur Qualität eines Agenten mit zufälliger Bewegung. Was den \emph{tournament factor p} betrifft, ist für XCS das Maximum bei \(0,88\) (Geschwindigkeit 1) bzw. \emph{0,80} (Geschwindigkeit 2).\\

Bei SXCS ist deutlich zu sehen, dass eine andauernde \emph{exploit} Phase bei beiden Geschwindigkeiten im Vergleich zu abwechselnden \emph{explore}/\emph{exploit} Phasen deutlich benachteiligt ist, teilweise sogar schlechter abschneidet als XCS. Die Maximalwerte bei SXCS liegen im Bereich von \(0,72\) bis \(0,88\) für Geschwindigkeit 1 und mit langsamer Steigung bei \(0,92\) für Geschwindigkeit 2. Ein sinnvoller Kompromiss erscheint hier deshalb \(0,84\) als Wert für den \emph{tournament factor p} zu benutzen.

\begin{figure}[htbp]
\centerline{	
\includegraphics{test_tournament_selection_direction_1.eps}
}
\caption[Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (Zielobjekt mit einfacher Richtungsänderung, Geschwindigkeit 1)]{Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (Zielobjekt mit einfacher Richtungsänderung, Geschwindigkeit 2, Säulenszenario, 2000 Schritte)}
\label{test_tournament_selection_direction_1:fig}
\end{figure}

\begin{figure}[htbp]
\centerline{	
\includegraphics{test_tournament_selection_direction_2.eps}
}
\caption[Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (Zielobjekt mit einfacher Richtungsänderung, Geschwindigkeit 1)]{Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (Zielobjekt mit einfacher Richtungsänderung, Geschwindigkeit 2, Säulenszenario, 2000 Schritte)}
\label{test_tournament_selection_direction_2:fig}
\end{figure}

Im Falle eines Zielobjekts mit intelligenter Bewegung (Abbildung~\ref{test_tournament_selection_intelligent_1:fig} mit Geschwindigkeit 1 und Abbildung~\ref{test_tournament_selection_intelligent_2:fig} mit Geschwindigkeit 2) fällt direkt ins Auge, dass eine abwechselnde \emph{explore}/\emph{exploit} Phase nicht vorteilhaft für einen SXCS Agenten ist. XCS erreicht ein ziemlich konstantes Ergebnis im Bereich von \(0,76\) bis \(0,92\), während SXCS mit andauernder \emph{exploit} Phase bei einem Wert von um die \(0,80\) den Maximalwert besitzt.\\

\begin{figure}[htbp]
\centerline{	
\includegraphics{test_tournament_selection_intelligent_1.eps}
}
\caption[Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (intelligentes Zielobjekt, Geschwindigkeit 1)]{Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (intelligentes Zielobjekt, Geschwindigkeit 1, Säulenszenario, 2000 Schritte)}
\label{test_tournament_selection_intelligent_1:fig}
\end{figure}

\begin{figure}[htbp]
\centerline{	
\includegraphics{test_tournament_selection_intelligent_1.eps}
}
\caption[Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (intelligentes Zielobjekt, Geschwindigkeit 2)]{Vergleich verschiedener Werte $p$ für Auswahlart \emph{tournament selection} (intelligentes Zielobjekt, Geschwindigkeit 2, Säulenszenario, 2000 Schritte)}
\label{test_tournament_selection_intelligent_2:fig}
\end{figure}

Insgesamt bestätigt die Untersuchung also, dass \(p = 0,84\) für diese Szenarien sinnvoll ist und somit die beste Aktion also mit \(p = 84\%\) Wahrscheinlichkeit, die zweitbeste mit ca. \((1,0-p)p \approx 13\%\) Wahrscheinlichkeit, die drittbeste mit ca. \((1,0-p)^{2}p \approx 2\%\) Wahrscheinlichkeit und die schlechteste Aktion mit ca. \((1,0-p)^{3}p \approx 1\%\) Wahrscheinlichkeit gewählt werden.\\
Außerdem kann man erkennen, dass bei einem sich intelligent verhaltenden Zielobjekt eine andauernde \emph{exploit} Phase die beste Wahl ist. Dies wird in Kapitel~\ref{test_auswahlarten:sec} relevant und dort auch näher diskutiert.\\


\subsection{Übersicht über alle Parameterwerte}

\begin{table}[ht]
\caption{Verwendete Parameter (soweit nicht anders angegeben) und Standardparameter}
\centering
\begin{tabular}{c c c}
\hline\hline
Parameter & Wert & Standardwert (siehe~\cite{butz01algorithmic})\\ [0.5ex]
\hline
max population \(N\) & \textbf{256} (siehe Kapitel~\ref{sec:max_population_parameter}) & [so, dass kein \emph{covering} nötig]\\
max value \(\rho\) & \textbf{1,0} (siehe Kapitel~\ref{epsilon0:sec}) & [10000]\\
fraction mean fitness \(\delta\) & 0,1 & [0,1]\\
deletion threshold \(\theta_{\mathrm{del}}\) & 20,0 & [\(\sim\) 20,0]\\
subsumption threshold \(\theta_{\mathrm{sub}}\) & 20,0 & [20,0+]\\
covering \(\#\) probability \(P_{\#}\) & 0,33 & [\(\sim\) 0,33]\\
GA threshold \(\theta_{\mathrm{GA}}\) & 25 & [25-50]\\
mutation probability \(\mu\) & \(0,05\) & [0,01-0,05]\\
prediction error reduction & 0,25 & [0,25]\\
fitness reduction & \(0,1\) & [0,1]\\

reward prediction init \(p_{i}\) & 0,01 & [\(\sim\) 0]\\
prediction error init \(\epsilon_{i}\) & 0,0 & [0,0]\\
fitness init \(F_{i}\) & \(0,01\) &  [0,01]\\
condition vector & \textbf{leer} (siehe Kapitel~\ref{sec:random_init}) &  [zufällig oder leer]\\
numerosity & 1 & [1]\\
experience & 0 & [0]\\

accuracy equality \(\epsilon_{0}\) & \textbf{0,01} (siehe Kapitel~\ref{epsilon0:sec}) & [\emph{1\% des größten Werts}]\\
accuracy calculation \(\alpha\) & 0,1 & [0,1]\\
accuracy power \(\nu\) & 5,0 & [5,0]\\
reward prediction discount \(\gamma\) & 0,71 & [0,71]\\

learning rate \(\beta\) & \textbf{0,001 - 0,01} (siehe Kapitel~\ref{sec:learnrate_parameter}) & [0,1-0,2]\\

exploration probability & 0,5 (siehe Kapitel~\ref{subsummation:sec}) & [\(\sim\) 0,5]\\
tournament factor & 0,84 (siehe Kapitel~\ref{tournament_factor_test:sec}) & [-]\\ [0.5ex]

\hline
\end{tabular}
\label{table:lcs_parameter}
\end{table}






