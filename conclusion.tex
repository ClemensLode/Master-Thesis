\chapter{Zusammenfassung, Ergebnis und Ausblick}
\label{conclusion:cha}


\section{Zusammenfassung}
Zu Beginn wurde auf die Szenariodefinition und die Fähigkeiten der Agenten eingegangen. Anhand von Beispielen heuristischer Agenten wurden einige Grundeigenschaften der präsentierten Szenarien als Vorbereitung für die Analyse der Learning Classifier Systeme bestimmt. Nach der Einführung in LCS, der Beschreibung des Standardverfahren XCS und der angepassten Implementierung für Überwachungsszenarios konnten dann umfangreiche Tests ausgeführt werden. Danach wurde durch die Hinzunahme von der Möglichkeit zur Kommunikation eine angepasste Implementierung für verzögerten Reward definiert auf Basis dessen dann mehrere Varianten für die Weitergabe des Rewards vorgestellt, analysiert und verglichen wurden.

\section{Ergebnis}
Das wesentliche Ergebnis ist, dass die Implementierung des XCS auf  Überwachungsszenarios ausgeweitet werden kann ohne wesentliche Veränderungen am Algorithmus vorzunehmen. Die alleinige Anpassung des XCS Multistepverfahrens, dass ein neues Problem gestartet wird, wann immer sich das Ziel in Überwachungsreichweite befand führte nicht zum Erfolg, die Ergebnisse waren nicht besser als ein sich zufällig bewegender Agent. Erst durch Verknüpfung des Rewards mit dem zeitlichen Abstand zu einer Änderung des Zustands führte zu deutlich besseren Ergebnissen.\\
Desweiteren wurde untersucht, inwiefern sich der Austausch an minimaler Information unter den Agenten, ohne zentrale Steuerung oder globalem Regeltausch, auf die Qualität auswirkt. Zwar gab es vereinzelt positive Effekte, diese waren jedoch auf andere Faktoren zurückzuführen.

\section{Ausblick}
Weitere Untersuchungen sind nötig um zu bestimmen, inwiefern Kommunikation, beispielsweise mit einer größeren Zahl an besseren Sensoren, zu einem besseren Ergebnis führen kann. TODO\\
Vom theoretischen Standpunkt ist noch zu klären, warum genau der zeitliche Abstand zum Erfolg geführt hat und wo die Grenzen hierfür liegen. 


\chapter{Verwendete Hilfsmittel und Software}

Zu Beginn stellte sich die Frage, welche Software zu benutzen ist, da es sich um ein recht komplexe Problemstellung handelt. Begonnen habe ich mit der YCS Implementierung von TODO. Sie ist in der Literatur wenig vertreten, die Implementierung bot aber einen guten Einstieg in das Thema, da sie sich auf das Wesentliche beschränkte und keine Optimierungen enthielt.

Der nächste Schritt war zu entscheiden, auf welchem System die Agenten simuliert werden sollen. Unter einer Reihe von vorhandenen Implementierungen entschied ich mich für eine eigene Implementation. 
Wesentlicher Grund war die Unerfahrenheit mit den Lösungen (und der damit verbundenen Einarbeitungszeit) wie auch Überlegungen bzgl. der Geschwindigkeit, dem Speicherverbrauch und der Kompatibilität. TODO

Das Programm und die zugehörige Oberfläche zum Erstellen von Test-Jobs wurden in Netbeans 6.5 programmiert.

Grafiken wurden mittels GnuPlot erstellt.

Grafiken der Grid-Konfiguration wurden im Programm mittels GifEncode TODO erste
 * @version 0.90 beta (15-Jul-2000)
 * @author J. M. G. Elliott (tep@jmge.net)

Wesentlicher Bestandteil der Konfigurationsoberfläche war auch eine Automatisierung der Erstellung von Konfigurationsdateien, Batchdateien (für ein Einzelsystem und für JoSchKA) zum Testen einer ganzen Reihe von Szenarien und auch GnuPlot Skripts.

Speicherverbrauch

Speicherung der Agentenpositionen und des Grids verbrauchen fast keinen Speicher TODO
Wesentlicher Faktor waren die LCS Systeme mit ihren ClassifierSets TODO

OpenOffice

LEd Latex


Speicherprobleme JAVA GB

\section{Beschreibung des Konfigurationsprogramms}

\begin{figure}[htbp]
\centerline{	
%\includegraphics{agent_configuration.eps}
}
\caption[Screenshot des Konfigurationsprogramms] {Screenshot des Konfigurationsprogramms}
\label{agent_configuration:fig}
\end{figure}



\begin{thebibliography}{99}
\bibitem{Butz} {\sc Butz, M. \& Wilson, S.W.:}  \textit{An Algorithmic Description of XCS}, 2001.
In P-L. Lanzi, W. Stolzmann \& S.W. Wilson (eds) Advances in Learning Classifier Systems: IWLCS 2000. Springer, pp253-272.

\bibitem{Butz2000} {\sc Butz, M.:} \textit{XCSJava 1.0: An implementation of the XCS classifier system in Java}
IlliGAL Report No. 2000027, June, 2000
\url{http://www.illigal.uiuc.edu/pub/papers/IlliGALs/2000027.ps.Z}

\bibitem{Bull} {\sc Larry Bull:}  \textit{A Simple Accuracy-Based Learning Classifier System}, 
\url{http://www2.cmp.uea.ac.uk/~it/ycs/ycs.pdf}

\bibitem{Hamer} 
{\sc Carol Hamer}, \textit{J2ME Games With MIDP2}, Apress, 2004,
ISBN 1-590-59382-0
\url{http://www.java-tips.org/java-me-tips/midp/how-to-create-a-maze-game-in-j2me-3.html}


The weight vector w of covering
classifiers is randomly initialized with values from [-1,1]; all
the other parameters are initialized as in XCS (see [4]).
[4] Martin V. Butz and Stewart W. Wilson. An algorithmic description of
XCS. Journal of Soft Computing, 6(3–4):144–153, 2002.

\bibitem{Butz2005} {\sc Martin V. Butz, David E. Goldberg, Pier Luca Lanzi}, \textit{Gradient descent methods in learning classifier systems: Improving XCS performance in multistep problems}
IEEE Transaction on Evolutionary Computation, 9(5):452–473, October 2005.

Pier Luca Lanzi, Daniele Loiacono, Stewart W. Wilson, and David E.
Goldberg. XCS with Computed Prediction in Continuous Multistep
Environments. In Proceedings of the IEEE Congress on Evolutionary
Computation – CEC-2005, pages 2032–2039, Edinburgh, UK, September
2005. IEEE.


OCS, Central planning:
\bibitem{Takadama} {\sc Keiki Takadama, Koichiro Hajiri, Tatsuya Nomura, Michio Okada, Shinichi Nakasuka, Katsunori Shimohara} \textit{Learning model for adaptive behaviors as an organized group of swarm robots}
In Artif Life Robotics (1998) 2 : 123-128, ISAROB 1998


\bibitem{Butz2006} {\sc Martin V. Butz} \textit{The XCS Classifier System}
In Studies in Fuzziness and Soft Computing, Springer, 2006, pp51-64.
ISBN 978-3-540-25379-2

\bibitem{Butz2006a} {\sc Martin V. Butz} \textit{Simple Learning Classifier Systems}
In Studies in Fuzziness and Soft Computing, Springer, 2006, pp51-64.
ISBN 978-3-540-25379-2

\bibitem{Wilson1995} {\sc Stewart W. Wilson:} \textit{Classifier Fitness Based on Accuracy}. 
Evolutionary Computation 3(2): 149-175 (1995)


\bibitem{Banzhaf} {\sc W. Banzhaf, J. Daida, A. E. Eiben, M. H. Garzon, V. Honavar, M. Jakiela and R. E. Smith} \textit{“Extending the representation of classifier conditions, Part I: From binary to Messy coding,”}
in Proc. Genetic Evol. Comput. Conf., Eds., 1999b, pp. 337–344.

\bibitem{Barry} {\sc A. M. Barry} \textit{“The stability of long action chains in XCS,”}, 
Soft Comput.—A Fusion Foundations, Methodologies, Applicat., vol. 6, no.
3–4, pp. 183–199, 2002.

\bibitem{xcs1} \textit{“Classifier fitness based on accuracy,”} Evol. Comput., vol. 3,
no. 2, pp. 149–175, 1995

\bibitem{xcs2} {\sc J. R. Koza,W. Banzhaf, K. Chellapilla, K. Deb,
M. Dorigo, D. B. Fogel, M. H. Garzon, D. E. Goldberg, H. Iba, and R.
Riolo} \textit{“Generalization in the XCS classifier system,”}
in Proc. 3rd Ann. Conf. Genetic Program., , Eds., 1998, pp. 665–674.


\bibitem{Butz2003} {\sc M. V. Butz, K. Sastry, and D. E. Goldberg:} \textit{“Tournament selection: Stable fitness pressure in XCS,”}
 in Lecture Notes in Computer Science,
E. Cantú-Paz, J. A. Foster, K. Deb, D. Davis, R. Roy, U.-M. O’Reilly,
H.-G. Beyer, R. Standish, G. Kendall, S. Wilson, M. Harman, J.
Wegener, D. Dasgupta, M. A. Potter, A. C. Schultz, K. Dowsland, N.
Jonoska, and J. Miller, Eds. Chicago, IL, Jul. 12–16, 2003, vol. 2724,
Proc. Genetic and Evol. Comput., pp. 1857–1869.

\end{thebibliography}
