\chapter{XCS}\label{lcs:cha}

TODO die ausführliche DIskussion der Parameter ist notwendig, da der Unterschied zum zufälligen Agenten so gering ist und keine Vergleichsarbeiten existieren!


Jeder Agent besitzt ein unabhängiges, sogenanntes \emph{eXtended Classifier System} (XCS), welches einem speziellen \emph{learning classifier system} (LCS) entspricht. Ein LCS ist ein evolutionäres Lernsystem, das aus einer Reihe von \emph{classifier} Regeln besteht, die zusammen ein sogenanntes \emph{classifier set} bilden (siehe Kapitel~\ref{classifier:sec}). Eine allgemeine Einführung in LCS findet sich z.B. in~\cite{Butz2006a}.\\
Im Folgenden konzentrieren sich die Ausführungen auf den Teil, der relevant für das Verständnis der in Kapitel~\ref{lcs_variants:cha} vorgestellten XCS Varianten ist (für eine umfassende Beschreibung von XCS soll auf \cite{Butz2006} verwiesen werden). 

\begin{figure}[H]
\setbox0\vbox{\small
Im Wesentlichen besteht ein XCS aus folgenden Elementen:
\begin{enumerate}

\item Einer Menge aus Regeln, sogenannte \emph{classifier} (siehe Kapitel~\ref{classifier:sec}), die zusammen ein \emph{classifier set} bilden,

\item einem Mechanismus zur Auswahl einer Aktion aus dem \emph{classifier set} (siehe Kapitel~\ref{auswahlart:sec}),

\item einem Mechanismus zur Zusammenfassung aller \emph{classifier} aus dem \emph{classifier set} mit gleicher Aktion zu einer \emph{action set} Liste,

\item einem Mechanismus zur Evolution der \emph{classifier} (mittels genetischer Operatoren, siehe Kapitel~\ref{genetische_operatoren:sec}) sowie

\item einem Mechanismus zur Bewertung der \emph{classifier} (mittels \emph{reinforcement learning}, siehe Kapitel~\ref{bewertung:sec})

\end{enumerate}
}
\centerline{\fbox{\box0}}
\end{figure}

Während die ersten drei Punkte bei allen hier vorgestellten XCS Varianten identisch sind, gibt es wesentliche Unterschiede bei der Bewertung der \emph{classifier}. Diese werden gesondert in Kapitel~\ref{lcs_variants:cha} im Einzelnen besprochen. Im Folgenden werden nun Punkt 1, 2 und 3 näher betrachtet und das Kapitel mit einer Diskussion und Analyse der XCS Parameter in Kapitel~\ref{cha:parameter} abgerundet.


\section{Classifier}\label{classifier:sec}

Ein \emph{classifier} besteht aus einer Anzahl im folgenden diskutierten Variablen die anhand der in Kapitel~\ref{cha:parameter} aufgelisteten Werte initialisiert werden. Wesentliche Teile sind der \emph{condition} Vektor (Kapitel~\ref{condition_vector:sec}) und der \emph{action} Wert (Kapitel~\ref{action_wert:sec}), alle restlichen Variablen dienen zur Berechnung der Wahrscheinlichkeit mit der der \emph{classifier} ausgewählt und dessen \emph{action} Wert ausgeführt wird.\\


\subsection{Der \emph{condition} Vektor}\label{condition_vector:sec}

Der \emph{condition} Vektor gibt die Kondition an, in welchen Situationen der zugehörige \emph{classifier} ausgewählt werden kann, d.h. welche Sensordatensätze der jeweilige \emph{classifier} erkennt. Der Aufbau des Vektors (siehe Abbildung~\ref{gruppen_condition_vector:fig}) entspricht dem Vektor der über die Sensoren erstellt wird (siehe Kapitel~\ref{sensordatensatz:sec}). Eine wesentliche Erweiterung des \emph{condition} Vektors stellen sogenannte Platzhalter dar, die es dem \emph{condition} Vektor erlauben, mehrere verschiedene Sensordatensätze zu erkennen (siehe Kapitel~\ref{platzhalter:sec}).

\begin{figure}[htbp]
\centerline{	
$\underbrace{z_{s_{N}} z_{r_{N}} z_{s_{O}} z_{r_{O}} z_{s_{S}} z_{r_{S}} z_{s_{W}} z_{r_{W}}}_{Erste~Gruppe~(Zielobjekt)}
\underbrace{a_{s_{N}} a_{r_{N}} a_{s_{O}} a_{r_{O}} a_{s_{S}} a_{r_{S}} a_{s_{W}} a_{r_{W}}}_{Zweite~Gruppe~(Agenten)}
\underbrace{h_{s_{N}} h_{r_{N}} h_{s_{O}} h_{r_{O}} h_{s_{S}} h_{r_{S}} h_{s_{W}} h_{r_{W}}}_{Dritte~Gruppe~(Hindernisse)}$
}
\caption[Einteilung des \emph{condition} Vektors] {Einteilung des \emph{condition} Vektors in drei Gruppen}
\label{gruppen_condition_vector:fig}
\end{figure}



\subsection{Der \emph{action} Wert}\label{action_wert:sec}

Wird ein \emph{classifier} ausgewählt, wird eine bestimmte Aktion ausgeführt, die durch den \emph{action} Wert determiniert ist. Im Rahmen dieser Arbeit entsprechen diese Aktionsmöglichkeiten den 4 Bewegungsrichtungen, die in Kapitel~\ref{agents:cha} besprochen wurden.\\


\subsection{Der \emph{fitness} Wert}

Der \emph{fitness} Wert soll die allgemeine Genauigkeit des \emph{classifier}
repräsentieren und wird über die Zeit hinweg sukzessive an die beobachteten \emph{reward} Werte angepasst. Hier erstreckt sich der Wertebereich zwischen \(0.0\) und \(1.0\) (maximale Genauigkeit). Insbesondere eines der ersten Werke zu XCS \cite{wilson:95} beschäftigte sich mit diesem Aspekt der Genauigkeit.\\


\subsection{Der \emph{reward prediction} Wert}

Der \emph{reward prediction} Wert des \emph{classifier} stellt die Höhe des \emph{reward} Werts dar, von dem der \emph{classifier} erwartet, dass er ihn bei der nächsten Bewertung erhalten wird.\\


\subsection{Der \emph{reward prediction error} Wert}

Der \emph{reward prediction error} Wert soll die Genauigkeit des \emph{classifier} bzgl. des \emph{reward prediction} Werts (die durchschnittliche Differenz zwischen \emph{reward prediction} und \emph{reward}) repräsentieren. U.a. auf Basis dieses Werts wird der \emph{fitness} Wert des \emph{classifier} angepasst.\\


\subsection{Der \emph{experience} Wert}

Mit dem \emph{experience} Wert des \emph{classifier} wird die Anzahl repräsentiert, wie oft ein \emph{classifier} aktualisiert wurde, also wieviel Erfahrung er sammeln konnte. Im Wesentliche	n dient dieser Wert als Entscheidungshilfe, ob auf die anderen Werte des \emph{classifier} vertraut werden kann bzw. ob der \emph{classifier} als unerfahren gilt und somit z.B. bei Löschung und Subsummation gesondert behandelt werden muss.\\


\subsection{Der \emph{numerosity} Wert}

Durch Subsummation (siehe Kapitel~\ref{subsummation:sec} und Kapitel~\ref{genetische_operatoren:sec}) können \emph{classifier} eine Rolle als \emph{macro classifier} spielen, d.h. \emph{classifier} die andere \emph{classifier} in sich beinhalten. Der \emph{numerosity} Wert gibt an, wieviele andere, sogenannte \emph{micro classifier} sich in dem jeweiligen \emph{classifier} befinden. Was die Implementation betrifft sei Kapitel~\ref{corrected_numerosity_function:sec} zu erwähnen, verglichen mit der originalen Implementierung wurden einige Änderungen vorgenommen.\\



\section{Vergleich des \emph{condition} Vektors mit den Sensordaten}\label{platzhalter:sec}

Neben den zu den Sensordaten korrespondierenden Werten \(0\) und \(1\) soll es noch einen dritten Zustand als Teil des \emph{condition} Vektors geben, den Platzhalter "`\#"'. Dieser soll anzeigen, dass beim Vergleich zwischen dem \emph{condition} Vektor und den Sensordaten diese Stelle ignoriert werden soll. Eine Stelle im \emph{condition} Vektor mit Platzhalter gilt dann also als äquivalent zur korrespondierenden Stelle in den Sensordaten, egal ob sie mit \(0\) oder \(1\) belegt ist. Ein Vektor, der ausschließlich aus Platzhaltern besteht, würde somit bei der Auswahl immer in Betracht gezogen werden, da er auf alle möglichen Kombinationen der Sensordaten passt. Umgekehrt können dadurch bei der Auswahl der \emph{classifier} mehrere \emph{classifier} auf einen gegebenen Sensordatenvektor passen. Diese bilden dann die sogenannte \emph{match set} Liste, aus welchem dann wie in Kapitel~\ref{auswahlart:sec} beschrieben der eigentliche \emph{classifier} ausgewählt wird.\\
Im Folgenden wird nun untersucht, welche Sensordatensätze ein \emph{condition} Vektor erkennt (siehe Kapitel~\ref{erkennung_sensordatenpaar:sec}), und zum anderen, auf welche Weise man ähnliche \emph{classifier} zusammenlegen kann (siehe Kapitel~\ref{subsummation:sec}).

\subsection{Erkennung von Sensordatenpaare}\label{erkennung_sensordatenpaar:sec}

Beim Vergleich der Sensordaten und Daten aus dem \emph{condition} Vektor werden immer jeweils zwei Paare herangezogen. In Kapitel~\ref{sensoren:sec} wurde erwähnt, dass der Fall \((0/1\)) in den Sensordaten nicht auftreten kann, weswegen (um die Aufgabe nicht unnötig zu erschweren) ein Datenpaar \((0/1\)) im \emph{condition} Vektor äquivalent zum Datenpaar \((1/1\)) sein soll, es damit also eine gewisse Redundanz gibt. Daraus folgt, dass auch das Datenpaar \((0/\#)\) zu \((\#/\#)\) äquivalent ist, also beide Datenpaare die selben Sensordatenpaare erkennen. 


\begin{figure}[H]
\setbox0\vbox{\small
Es ergeben sich also folgende Fälle:
\begin{enumerate}
\item Sensorenpaar \((0/0)\) wird erkannt von \((0/0)\), \((\#, 0)\), \((0, \#)\), \((\#, \#)\),
\item Sensorenpaar \((1/0)\) wird erkannt von \((1/0)\), \((\#, 0)\), \((1, \#)\), \((\#, \#)\),
\item Sensorenpaar \((1/1)\) wird erkannt von \((1/1)\), \((\#, 1)\), \((1, \#)\), \((\#, \#)\), \((0/1)\), \((0/\#)\);
\end{enumerate}
}
\centerline{\fbox{\box0}}
\end{figure}

Beispielsweise würden folgende Sensordaten von den folgenden \emph{condition} Vektoren erkannt:
\begin{verbatim}
Sensordaten:
(Zielobjekt in Sicht im Norden, Agent im Sicht im Süden, 
Hindernisse im Westen und Osten)
10 00 00 00 . 00 00 11 00 . 00 11 00 11

Beispiele für erkennende condition Vektoren:
10 00 00 00 . ## ## ## ## . 00 ## ## ##
## ## ## ## . ## ## #1 00 . 00 11 ## ##
#0 ## ## ## . ## ## 01 ## . ## 11 ## 11
\end{verbatim}



\subsection{Subsummation von \emph{classifier}}\label{subsummation:sec}

Die Benutzung von den oben erwähnten Platzhaltern (Kapitel~\ref{platzhalter:sec}) erlaubt es dem XCS mehrere \emph{classifier} zu zusammenzulegen, wodurch die Gesamtzahl der \emph{classifier} sinkt und somit Erfahrungen, die ein XCS Agent sammelt, nicht unbedingt mehrfach gemacht werden müssen. Die dahinter stehende Annahme ist, dass es Situationen gibt, in denen der Gewinn der durch Unterscheidung zwischen zwei verschiedenen Sensordatensätzen geringer ist als die Ersparnis durch das Zusammenlegen beider \emph{classifier}, d.h. dem Ignorieren der Unterschiede.\\

Besitzt ein \emph{classifier} sowohl einen genügend großen \emph{experience} Wert als auch einen ausreichend kleinen \emph{reward prediction error} Wert, so kann er als sogenannter \emph{subsumer} auftreten. Andere \emph{classifier} (in derselben \emph{action set} Liste, also mit gleichem \emph{action} Wert) werden durch den \emph{subsumer} ersetzt, sofern der von ihnen abgedeckte Sensordatenbereich eine Teilmenge des von dem \emph{subsumer} abgedeckten Bereichs ist, der \emph{subsumer} also an allen Stellen des \emph{condition} Vektors entweder denselben Wert wie der zu subsummierende \emph{classifier} oder einen Platzhalter besitzt.\\






\section{Ablauf eines XCS}\label{ablauf_lcs:sec}

\begin{figure}[H]
\setbox0\vbox{\small
Ein XCS läuft wie folgt ab:
\begin{enumerate}
\item Vervollständigung der \emph{classifier} Liste (\emph{covering}, siehe Kapitel~\ref{covering:sec}),
\item Auswahl auf die Sensordaten passender \emph{classifier} (\emph{match set} Liste, siehe Kapitel~\ref{matching:sec}),
\item Bestimmung der Auswahlart und Auswahl der Aktion (\emph{explore/exploit}, siehe Kapitel~\ref{auswahlart:sec}),
\item Erstellung der zur Aktion zugehörigen Liste von \emph{classifier} (\emph{action set} Liste, siehe Kapitel~\ref{actionSet:sec});
\end{enumerate}
}
\centerline{\fbox{\box0}}
\end{figure}

Im Folgenden werden die einzelnen Punkte besprochen TODO


\subsection{Abdeckung aller Aktionen durch \emph{covering}}\label{covering:sec}

Das \emph{covering} untersicht die Menge aller \emph{classifier} aus dem letzten \emph{match set} (siehe Kapitel~\ref{matching:sec}), ob für jede mögliche Aktion jeweils mindestens ein \emph{classifier} vorhanden ist. Ist dies nicht der Fall, wird ein neuer \emph{classifier} mit dieser Aktion als seinen \emph{action} Wert und einem \emph{condition} Vektor, der auf den letzten Sensordatensatz passt, erstellt und in die Population eingefügt. So wird sichergestellt, dass alle Situationen und Aktionen abgedeckt sind. Ist die Populationsgröße \(N\) zu niedrig, kommt es zum \emph{trashing}, d.h. es werden andauernd neue \emph{classifier} erstellt, gleichzeitig müssen aber (brauchbare) alte \emph{classifier} gelöscht werden. In Kapitel~\ref{sec:max_population_parameter} in Abbildung~\ref{neuerstellte_classifier_maxpop:fig} sieht man beispielsweise, dass in dem dortigen Szenario mindestens bis zu einer Größe von 64 dies regelmäßig passiert.

\subsection{Die \emph{match set} Liste}\label{matching:sec}

In der \emph{match set} Liste werden jeweils alle \emph{classifier} gespeichert, die den letzten Sensordatensatz erkannt haben. Sie entspricht dem \emph{predictionArray} in der originalen Implementierung von XCS in~\cite{Butz_xcsclassifier}, dort werden außerdem Vorberechnungen zur Auswahl der nächsten Aktion durchgeführt und die Ergebnisse gespeichert, die insbesondere in Kapitel~\ref{auswahlart:sec} von Bedeutung sind (die sogenannten \emph{predictionFitnessProductSum} Werte).


\subsection{Die \emph{action set} Liste}\label{actionSet:sec}

Eine \emph{action set} Liste ist jeweils einer Zeiteinheit zugeordnet. Dort werden jeweils alle \emph{classifier} gespeichert, die zu diesem Zeitpunkt denselben \emph{action} Wert besitzen wie der für die Bewegung bestimmte \emph{classifier}. In der Standardimplementation von XCS wird jeweils nur das die letzte \emph{action set} Liste gespeichert, während in SXCS eine ganze Reihe (bis zu \emph{maxStackSize} Stück) gespeichert werden (siehe Kapitel~\ref{sxcs_variant:sec}).


\subsection{Bewertung der Aktionen (\emph{base reward}) TODO}\label{bewertung:sec}

XCS ist darauf ausgelegt, dass es eine komplette, genaue und möglichst allgemeine Darstellung einer \emph{reward} Funktion darstellt. Bei einer Problemstellung, die mit dem \emph{single step} Verfahren gelöst werden kann, entspricht die optimale Darstellung der \emph{reward} Funktion durch das XCS gleichzeitig auch der Lösung des eigentlichen Problems. Beispielsweise beim oben erwähnten \emph{6-Multiplexer} Problem prüft die \emph{reward} Funktion, ob das XCS aus den 4 Datenbits anhand der 2 Steuerbits das richtige Datenbit gewählt hat, also ob das XCS so wie ein \emph{6-Multiplexer} funktioniert. Wesentliche Voraussetzung für das \emph{single step} Verfahren ist, dass der Agent globale Information besitzt, also in einem Schritt möglichst alle Informationen zur Lösung des Problems zur Verfügung hat, um die jeweilige Lösung zu bewerten.\\

Bei komplexeren Problemen, bei denen ein Agent nur lokale Informationen zur Verfügung hat (beispielsweise bei \emph{Maze~\(N\)} die angrenzenden Felder), liefert die \emph{reward} Funktion nur eine Teilinformation, beispielsweise "`1"' beim letzten Schritt auf das Ziel und "`0"' sonst. Diese Art von Bewertung, die der Agent direkt aus den Sensordaten berechnet, soll in diesem Zusammenhang im folgenden \emph{base reward} genannt werden.\\

Die Frage ist nun, wie diese Bewertung aus den Sensordaten berechnet wird. Für alle \(2^{24}\) Situationen (tatsächlich weniger, da es nur ein Zielobjekt gibt und bestimmte Situationen nicht auftreten können), die die Sensoren der Agenten erkennen können, könnte ein eigener \emph{base reward} Wert vergeben werden, weshalb sich die Frage nach dem Ziel des Ganzen stellt. Ziel ist es, die globale Aufgabe zu erfüllen, also mithilfe der Sensordaten über die Zeit hinweg ein möglichst akkurates Gesamtbild des Problems zu bilden um auf dieser Information aufbauend möglichst gute Entscheidungen zu treffen.\\

Die optimale Darstellung der \emph{reward} Funktion bei XCS in der \emph{multi step} Variante ist zum einen eine simple Abfrage, ob die Zielposition erreicht wurde ("`1"') oder nicht ("`0"') und zum anderen der Aufbau eines Gesamtbilds über die Weitergabe mittels des jeweiligen \emph{maxPrediction} Werts. Auf Basis dessen wird ein vereinfachter Gesamtweg gebildet (vereinfacht deshalb, weil Situationen und Aktionen in den \emph{classifier set} Listen gespeichert werden und nicht Aktionsreihenfolgen und/oder Positionsangaben zusammen mit der auszuführenden Aktion) und somit zumindest teilweise das Problem in ein \emph{single step} Problem überführt.\\

Der selbe Gedankengang muss bei einem Überwachungsszenario ausgeführt werden. Beim zweiten Teil der Frage (Darstellung des Gesamtproblems aus lokaler Information) kann man zwar, wie es in Kapitel~\ref{standardxcs:sec} getan wird, XCS einfach auf das Szenario fast ohne Änderung übertragen. Die Ergebnisse, wie sie in Kapitel~\ref{lcs_analysis:cha} gezeigt werden, sind dann aber nicht viel besser als ein sich zufällig bewegender Agent. Ein alternativer Weg, der dann in Kapitel~\ref{lcs_variants:cha} vorgestellt und in Kapitel~\ref{lcs_analysis:cha} signifikant bessere Ergebnisse erbringt, ist, den \emph{base reward} Werts nicht sukzessive weiterzugeben, sondern bei jedem Auftreten eines positiven \emph{base reward} Werts direkt alle bisherigen Aktionen (seit dem letzten Auftreten) absteigend mit dem Wert zu aktualisieren.\\

Übrig bleibt dann nur noch die Frage nach dem ersten Teil der Frage, also wie der \emph{base reward} selbst berechnet wird. Hierzu wurden verschiedene Ansätze ausprobiert, da aber weder ein Qualitätsgewinn festgestellt wurde, noch eine Verkomplizierung bei der Berechnung für die weitere Untersuchung hilfreich erschien, blieb es bei der einfachst möglichen Implementation. Diese bestand aus einer einfachen Abfrage, ob das Zielobjekt in Sichtweite ist oder nicht. Die Einbeziehung von Agenten und Hindernissen führte nicht zum Erfolg, vermutlich deshalb, weil die durch die Sensoren wahrgenommen Positionen zu unklar waren. Mit Sensoren, die exakte Positionen bestimmen können, wäre vorstellbar, dass z.B. kein positiver \emph{base reward} vergeben wird, wenn andere Agenten sich näher am Zielobjekt befinden.\\

Was die Implementierung betrifft, wird die mit der Bewertung zusammenhängende Funktion \emph{checkRewardPoints()} in Programm~\ref{multistep_calc_reward:pro} (Zeile 15) bzw. in Programm~\ref{sxcs_calc_reward:pro} (Zeile 16) aufgerufen.


%Foundations of Learning Classifier Systems By Larry Bull, Tim Kovacs
%Evolutionary pressures in XCS
%TODO Quelle?


\subsection{Genetische Operatoren}\label{genetische_operatoren:sec}

Es werden aus der jeweiligen \emph{action set} Liste zwei \emph{classifier} (die Eltern) zufällig ausgewählt und zwei neue \emph{classifier} (die Kinder) aus ihnen gebildet und in die Population eingefügt. Dabei wird mittels \emph{two-point crossover} ein neuer \emph{condition} Vektor generiert und der \emph{action} Wert auf den der Eltern gesetzt (da sie aus derselben \emph{action set} Liste stammen, ist der Wert beider Eltern identisch). Die restlichen Werte werden standardmäßig wie in Kapitel~\ref{cha:parameter} aufgelistet initialisiert. Werden Kinder in die Population eingefügt, deren \emph{action} Wert und \emph{condition} Vektor identisch mit existierenden \emph{classifier} ist, werden sie stattdessen subsummiert.\\
Da die Sensoren und somit auch der \emph{condition} Vektor aus drei in sich geschlossenen Gruppen bestehen, werden im Unterschied zur Standardimplementation beim \emph{crossing over} zwei feste Stellen benutzt, die die Gruppe für das Zielobjekt, die Gruppe für Agenten und die Gruppe für feste Hindernisse voneinander trennen.\\

Bezeichne \((z_1, a_1, h_1)\) bzw. \((z_2, a_2, h_2)\) jeweils die drei Gruppen (siehe Kapitel~\ref{condition_vector:sec}) des \emph{condition} Vektors des ersten bzw. zweiten ausgewählten Elternteils, dann können für die drei Gruppen der \emph{condition} Vektoren \((z_{1k}, a_{1k}, h_{1k})\) und \((z_{2k}, a_{2k}, h_{2k})\) der beiden Kinder folgende Kombinationen auftreten:

\[[(z_{1k}, a_{1k}, h_{1k}), (z_{2k}, a_{2k}, h_{2k})] = [(z_1, a_1, h_1) , (z_2, a_2, h_2)]\]
\[[(z_{1k}, a_{1k}, h_{1k}), (z_{2k}, a_{2k}, h_{2k})] = [(z_2, a_1, h_1) , (z_1, a_2, h_2)]\]
\[[(z_{1k}, a_{1k}, h_{1k}), (z_{2k}, a_{2k}, h_{2k})] = [(z_1, a_2, h_1) , (z_2, a_1, h_2)]\]
\[[(z_{1k}, a_{1k}, h_{1k}), (z_{2k}, a_{2k}, h_{2k})] = [(z_2, a_2, h_1) , (z_1, a_1, h_2)]\]
